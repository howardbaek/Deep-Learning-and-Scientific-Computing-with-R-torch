<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-99.9.9">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Deep Learning and Scientific Computing with R torch - 3&nbsp; Tensors</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./autograd.html" rel="next">
<link href="./what_is_torch.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./basics_overview.html">Getting familiar with torch</a></li><li class="breadcrumb-item"><a href="./tensors.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Tensors</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Deep Learning and Scientific Computing with R torch</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Getting familiar with torch</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./basics_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Overview</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./what_is_torch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">On <code>torch</code>, and how to get it</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tensors.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Tensors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./autograd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Autograd</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./optim_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Function minimization with <em>autograd</em></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./network_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">A neural network from scratch</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./modules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Modules</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./optimizers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Optimizers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./loss_functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Loss functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./optim_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Function minimization with L-BFGS</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./network_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Modularizing the neural network</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Deep learning with torch</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dl_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Overview</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Loading data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./training_with_luz.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Training with luz</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./image_classification_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">A first go at image classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./overfitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Making models generalize</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./training_efficiency.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Speeding up training</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./image_classification_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Image classification, take two: Improving performance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./image_segmentation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Image segmentation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tabular_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Tabular data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./time_series.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Time series</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./audio_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Audio classification</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Other things to do with torch: Matrices, Fourier Transform, and Wavelets</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./other_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Overview</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./matrix_computations_leastsquares.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Matrix computations: Least-squares problems</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./matrix_computations_convolution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Matrix computations: Convolution</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fourier_transform_dft.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Exploring the Discrete Fourier Transform (DFT)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fourier_transform_fft.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">The Fast Fourier Transform (FFT)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wavelets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Wavelets</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#whats-in-a-tensor" id="toc-whats-in-a-tensor" class="nav-link active" data-scroll-target="#whats-in-a-tensor"><span class="header-section-number">3.1</span> What’s in a tensor?</a></li>
  <li><a href="#creating-tensors" id="toc-creating-tensors" class="nav-link" data-scroll-target="#creating-tensors"><span class="header-section-number">3.2</span> Creating tensors</a>
  <ul class="collapse">
  <li><a href="#tensors-from-values" id="toc-tensors-from-values" class="nav-link" data-scroll-target="#tensors-from-values"><span class="header-section-number">3.2.1</span> Tensors from values</a></li>
  <li><a href="#tensors-from-specifications" id="toc-tensors-from-specifications" class="nav-link" data-scroll-target="#tensors-from-specifications"><span class="header-section-number">3.2.2</span> Tensors from specifications</a></li>
  <li><a href="#tensors-from-datasets" id="toc-tensors-from-datasets" class="nav-link" data-scroll-target="#tensors-from-datasets"><span class="header-section-number">3.2.3</span> Tensors from datasets</a></li>
  </ul></li>
  <li><a href="#operations-on-tensors" id="toc-operations-on-tensors" class="nav-link" data-scroll-target="#operations-on-tensors"><span class="header-section-number">3.3</span> Operations on tensors</a>
  <ul class="collapse">
  <li><a href="#summary-operations" id="toc-summary-operations" class="nav-link" data-scroll-target="#summary-operations"><span class="header-section-number">3.3.1</span> Summary operations</a></li>
  </ul></li>
  <li><a href="#accessing-parts-of-a-tensor" id="toc-accessing-parts-of-a-tensor" class="nav-link" data-scroll-target="#accessing-parts-of-a-tensor"><span class="header-section-number">3.4</span> Accessing parts of a tensor </a>
  <ul class="collapse">
  <li><a href="#think-r" id="toc-think-r" class="nav-link" data-scroll-target="#think-r"><span class="header-section-number">3.4.1</span> “Think R”</a></li>
  </ul></li>
  <li><a href="#reshaping-tensors" id="toc-reshaping-tensors" class="nav-link" data-scroll-target="#reshaping-tensors"><span class="header-section-number">3.5</span> Reshaping tensors</a>
  <ul class="collapse">
  <li><a href="#zero-copy-reshaping-vs.-reshaping-with-copy" id="toc-zero-copy-reshaping-vs.-reshaping-with-copy" class="nav-link" data-scroll-target="#zero-copy-reshaping-vs.-reshaping-with-copy"><span class="header-section-number">3.5.1</span> Zero-copy reshaping vs.&nbsp;reshaping with copy</a></li>
  </ul></li>
  <li><a href="#broadcasting" id="toc-broadcasting" class="nav-link" data-scroll-target="#broadcasting"><span class="header-section-number">3.6</span> Broadcasting</a>
  <ul class="collapse">
  <li><a href="#broadcasting-rules" id="toc-broadcasting-rules" class="nav-link" data-scroll-target="#broadcasting-rules"><span class="header-section-number">3.6.1</span> Broadcasting rules</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec:tensors" class="quarto-section-identifier"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Tensors</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="whats-in-a-tensor" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="whats-in-a-tensor"><span class="header-section-number">3.1</span> What’s in a tensor?</h2>
<p>To do anything useful with <code>torch</code>, you need to know about tensors. Not tensors in the math/physics sense. In deep learning frameworks such as TensorFlow and (Py-)Torch, <em>tensors</em> are “just” multi-dimensional arrays optimized for fast computation – not on the CPU only but also, on specialized devices such as GPUs and TPUs.</p>
<p>In fact, a <code>torch</code> <code>tensor</code> is like an R <code>array</code>, in that it can be of arbitrary dimensionality. But unlike <code>array</code>, it is designed for fast and scalable execution of mathematical calculations, and you can move it to the GPU. (It also has an extra capability of enormous practical impact – automatic differentiation – but we reserve that for the next chapter.)</p>
<p>Technically, a <code>tensor</code> feels a lot like an R6 object, in that you can access its fields and methods using <code>$</code>-syntax. Let’s create one and print it:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="dv">1</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>t1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 1
[ CPUFloatType{1} ]</code></pre>
<p>This is a tensor that holds just a single value, 1. It “lives” on the CPU, and its type is <code>Float</code> . Now take a look at the 1 in braces, <code>{1}</code>. This is <em>not</em> yet another indication of the tensor’s value. It indicates the tensor shape, or put differently: the space it lives in and the extent of its dimensions. Here, we have a one-dimensional tensor, that is, a vector. Just as in base R, vectors can consist of a single element only. (Remember that base R does not differentiate between <code>1</code> and <code>c(1)</code>).</p>
<p>We can use the aforementioned <code>$</code>-syntax to individually ascertain these properties, accessing the respective fields in the object one-by-one:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span>dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_Float</code></pre>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span>device</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_device(type='cpu')</code></pre>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span>shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 1</code></pre>
<p>We can also directly change some of these properties, making use of the tensor object’s <code>$to()</code> method:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> t1<span class="sc">$</span><span class="fu">to</span>(<span class="at">dtype =</span> <span class="fu">torch_int</span>())</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>t2<span class="sc">$</span>dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_Int</code></pre>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># only applicable if you have a GPU</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> t1<span class="sc">$</span><span class="fu">to</span>(<span class="at">device =</span> <span class="st">"cuda"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>t2<span class="sc">$</span>device</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_device(type='cuda', index=0)</code></pre>
<p>How about changing the shape? This is a topic deserving of treatment of its own, but as a first warm-up, let’s play around a bit. Without changing its value, we can turn this one-dimensional “vector tensor” into a two-dimensional “matrix tensor”:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>t3 <span class="ot">&lt;-</span> t1<span class="sc">$</span><span class="fu">view</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>t3<span class="sc">$</span>shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 1 1</code></pre>
<p>Conceptually, this is analogous to how in R, we can have a one-element vector as well as a one-element matrix:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(<span class="dv">1</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">matrix</span>(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 1

     [,1]
[1,]    1</code></pre>
<p>Now that we have an idea what a tensor is, let’s think about ways to create some.</p>
</section>
<section id="creating-tensors" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="creating-tensors"><span class="header-section-number">3.2</span> Creating tensors</h2>
<p>We’ve already seen one way to create a tensor: calling <code>torch_tensor()</code> and passing in an R value. This way generalizes to multi-dimensional objects; we’ll see a few examples soon.</p>
<p>However, that procedure can get unwieldy when we have to pass in lots of different values. Luckily, there is an alternative approach that applies whenever values should be identical throughout, or follow an apparent pattern. We’ll illustrate this technique as well in this section.</p>
<section id="tensors-from-values" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="tensors-from-values"><span class="header-section-number">3.2.1</span> Tensors from values</h3>
<p>Above, we passed in a one-element vector to <code>torch_tensor()</code>; we can pass in longer vectors just the same way:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_tensor</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 1
 2
 3
 4
 5
[ CPULongType{5} ]</code></pre>
<p>When given an R value (or a sequence of values), <code>torch</code> determines a suitable data type itself. Here, the assumption is that an integer type is desired, and <code>torch</code> chooses the highest-precision type available (<code>torch_long()</code> is synonymous to <code>torch_int64()</code>).</p>
<p>If we want a floating-point tensor instead, we can use <code>$to()</code> on the newly created instance (as we saw above). Alternatively, we can just let <code>torch_tensor()</code> know right away:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_tensor</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="at">dtype =</span> <span class="fu">torch_float</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 1
 2
 3
 4
 5
[ CPUFloatType{5} ]</code></pre>
<p>Analogously, the default device is the CPU; but we can also create a tensor that, right from the outset, is located on the GPU:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_tensor</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="at">device =</span> <span class="st">"cuda"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 1
 2
 3
 4
 5
[ CPUFloatType{5} ]</code></pre>
<p>Now, so far all we’ve been creating is vectors; what about matrices, that is, two-dimensional tensors?</p>
<p>We can pass in an R matrix just the same way:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_tensor</span>(<span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>, <span class="at">ncol =</span> <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 1  4  7
 2  5  8
 3  6  9
[ CPULongType{3,3} ]</code></pre>
<p>Look at the result. The numbers 1 to 9 appear column after column, just as in the R matrix we created it from. This may, or may not, be the intended outcome. If it’s not, just pass <code>byrow = TRUE</code> to the call to <code>matrix()</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_tensor</span>(<span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>, <span class="at">ncol =</span> <span class="dv">3</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 1  2  3
 4  5  6
 7  8  9
[ CPULongType{3,3} ]</code></pre>
<p>What about higher-dimensional data? Following the same principle, we can pass in an array:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_tensor</span>(<span class="fu">array</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">24</span>, <span class="at">dim =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
(1,.,.) = 
   1  13
   5  17
   9  21

(2,.,.) = 
   2  14
   6  18
  10  22

(3,.,.) = 
   3  15
   7  19
  11  23

(4,.,.) = 
   4  16
   8  20
  12  24
[ CPULongType{4,3,2} ]</code></pre>
<p>Again, the result follows R’s array population logic. If that’s not what you want, it is probably easier to build up the tensor programmatically.</p>
<p>Before you start to panic, though, think about how rarely you’ll need to do this. In practice, you’ll mostly be creating tensors from an R dataset. We’ll take a close look at that in the last subsection, “Tensors from datasets”. Before though, it is instructive to spend a little time inspecting that last output.</p>
<p>Here, pictorially, is the object we created (<a href="#fig-tensors-dimensions">fig.&nbsp;<span>3.1</span></a>). Let’s call the axis that extends to the right <code>x</code>, the one that goes into the page, <code>y</code>, and the one that points up, <code>z</code>. Then the tensor extends 4, 3, and 2 units, respectively, in the x, y, and z directions.</p>
<div id="fig-tensors-dimensions" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/tensors-dimensions.png" class="quarto-discovered-preview-image img-fluid figure-img" alt="A cube that extends 4, 3, and 2 units, respectively, in the x, y, and z directions."></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;3.1: A 4x3x2 tensor.</figcaption><p></p>
</figure>
</div>
<p>The array we passed to <code>torch_tensor()</code> prints like this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">array</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">24</span>, <span class="at">dim =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>, , 1

     [,1] [,2] [,3]
[1,]    1    5    9
[2,]    2    6   10
[3,]    3    7   11
[4,]    4    8   12

, , 2

     [,1] [,2] [,3]
[1,]   13   17   21
[2,]   14   18   22
[3,]   15   19   23
[4,]   16   20   24</code></pre>
<p>Compare that with how the tensor prints, above. <code>Array</code> and <code>tensor</code> slice the object in different ways. The tensor slices its values into <code>3x2</code> rectangles, extending up and to the back, one for each of the four <code>x</code>-values. The array, on the other hand, splits them up by <code>z</code>-value, resulting in two big <code>4x3</code> slices that go up and to the right.</p>
<p>Alternatively, we could say that the tensor starts thinking from the left/the “outside”; the array, from the right/the “inside”.</p>
</section>
<section id="tensors-from-specifications" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="tensors-from-specifications"><span class="header-section-number">3.2.2</span> Tensors from specifications</h3>
<p>There are two broad conditions when <code>torch</code>’s bulk creation functions will come in handy: For one, when you don’t care about individual tensor values, but only about their distribution. Secondly, if they follow some conventional pattern.</p>
<p>When we use bulk creation functions, instead of individual <em>values</em> we specify the <em>shape</em> they should have. Here, for example, we instantiate a 3x3 tensor, populated with standard-normally distributed values:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_randn</span>(<span class="dv">3</span>, <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
-0.6532  0.6557  2.0251
-0.7914 -1.7220  1.0387
 0.1931  1.0536 -0.2077
[ CPUFloatType{3,3} ]</code></pre>
<p>And here is the equivalent for values that are uniformly distributed between zero and one:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_rand</span>(<span class="dv">3</span>, <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 0.2498  0.5356  0.6515
 0.3556  0.5799  0.1284
 0.9884  0.4361  0.8040
[ CPUFloatType{3,3} ]</code></pre>
<p>Often, we require tensors of all ones, or all zeroes:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_zeros</span>(<span class="dv">2</span>, <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 0  0  0  0  0
 0  0  0  0  0
[ CPUFloatType{2,5} ]</code></pre>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_ones</span>(<span class="dv">2</span>, <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 1  1
 1  1
[ CPUFloatType{2,2} ]</code></pre>
<p>Many more of these bulk creation functions exist. To wrap up, let’s see how to create some matrix types that are common in linear algebra. Here’s an identity matrix:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_eye</span>(<span class="at">n =</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 1  0  0  0  0
 0  1  0  0  0
 0  0  1  0  0
 0  0  0  1  0
 0  0  0  0  1
[ CPUFloatType{5,5} ]</code></pre>
<p>And here, a diagonal matrix:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_diag</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 1  0  0
 0  2  0
 0  0  3
[ CPUFloatType{3,3} ]</code></pre>
</section>
<section id="tensors-from-datasets" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3" class="anchored" data-anchor-id="tensors-from-datasets"><span class="header-section-number">3.2.3</span> Tensors from datasets</h3>
<p>Now we look at how to create tensors from R datasets. Depending on the dataset itself, this process can feel “automatic” or require some thought and action.</p>
<p>First, let’s try <code>JohnsonJohnson</code> that comes with base R. It is a time series of quarterly earnings per Johnson &amp; Johnson share.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>JohnsonJohnson</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>      Qtr1  Qtr2  Qtr3  Qtr4
1960  0.71  0.63  0.85  0.44
1961  0.61  0.69  0.92  0.55
1962  0.72  0.77  0.92  0.60
1963  0.83  0.80  1.00  0.77
1964  0.92  1.00  1.24  1.00
1965  1.16  1.30  1.45  1.25
1966  1.26  1.38  1.86  1.56
1967  1.53  1.59  1.83  1.86
1968  1.53  2.07  2.34  2.25
1969  2.16  2.43  2.70  2.25
1970  2.79  3.42  3.69  3.60
1971  3.60  4.32  4.32  4.05
1972  4.86  5.04  5.04  4.41
1973  5.58  5.85  6.57  5.31
1974  6.03  6.39  6.93  5.85
1975  6.93  7.74  7.83  6.12
1976  7.74  8.91  8.28  6.84
1977  9.54 10.26  9.54  8.73
1978 11.88 12.06 12.15  8.91
1979 14.04 12.96 14.85  9.99
1980 16.20 14.67 16.02 11.61</code></pre>
<p>Can we just pass this to <code>torch_tensor()</code> and magically get what we want?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_tensor</span>(JohnsonJohnson)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
  0.7100
  0.6300
  0.8500
  0.4400
  0.6100
  0.6900
  0.9200
  0.5500
  0.7200
  0.7700
  0.9200
  0.6000
  0.8300
  0.8000
  1.0000
  0.7700
  0.9200
  1.0000
  1.2400
  1.0000
  1.1600
  1.3000
  1.4500
  1.2500
  1.2600
  1.3800
  1.8600
  1.5600
  1.5300
  1.5900
... [the output was truncated (use n=-1 to disable)]
[ CPUFloatType{84} ]</code></pre>
<p>Looks like we can! The values are arranged exactly the way we want them; quarter after quarter.</p>
<p>Magic? Not really. <code>torch</code> can only work with what it is given; and here, what it is given is actually a vector of <code>double</code>s arranged in quarterly order. The data just print the way they do because they are of class <code>ts</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">unclass</span>(JohnsonJohnson)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1]  0.71  0.63  0.85  0.44  0.61  0.69  0.92  0.55  0.72
[10] 0.77  0.92  0.60  0.83  0.80  1.00  0.77 0.92  1.00
[19] 1.24  1.00  1.16  1.30  1.45  1.25  1.26  1.38  1.86
[28] 1.56  1.53  1.59  1.83  1.86 1.53  2.07  2.34  2.25
[37] 2.16  2.43  2.70  2.25  2.79  3.42  3.69  3.60  3.60
[46] 4.32  4.32  4.05 4.86  5.04  5.04  4.41  5.58  5.85
[55] 6.57  5.31  6.03  6.39  6.93  5.85  6.93  7.74  7.83
[64] 6.12 7.74  8.91  8.28  6.84  9.54 10.26  9.54  8.73
[73] 11.88 12.06 12.15  8.91 14.04 12.96 14.85  9.99 16.20
[82] 14.67 16.02 11.61 
attr(,"tsp")
[1] 1960.00 1980.75    4.00</code></pre>
<p>So this went well. Let’s try another one. Who is not kept up at night, pondering trunk thickness of orange trees?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(Orange)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>Rows: 35
Columns: 3
$ Tree          &lt;ord&gt; 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,...
$ age           &lt;dbl&gt; 118, 484, 664, 1004, 1231, 1372, 1582,...
$ circumference &lt;dbl&gt; 30, 58, 87, 115, 120, 142, 145, 33, 69,...</code></pre>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_tensor</span>(Orange)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>Error in torch_tensor_cpp(data, dtype, device, requires_grad,
pin_memory) : R type not handled</code></pre>
<p>Which type is <em>not handled</em> here? It seems obvious that the “culprit” must be <code>Tree</code>, an ordered-factor column. Let’s first check if <code>torch</code> can handle factors:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="fu">c</span>(<span class="st">"a"</span>, <span class="st">"b"</span>, <span class="st">"c"</span>), <span class="at">ordered =</span> <span class="cn">TRUE</span>)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_tensor</span>(f)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 1
 2
 3
[ CPULongType{3} ]</code></pre>
<p>So this worked fine. Then what else could it be? The problem here is the containing structure, the <code>data.frame</code>. We need to call <code>as.matrix()</code> on it first. Due to the presence of the factor, though, this will result in a matrix of all strings, which is not what we want. Therefore, we first extract the underlying levels (integers) from the factor, and then convert the <code>data.frame</code> to a matrix:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>orange_ <span class="ot">&lt;-</span> Orange <span class="sc">%&gt;%</span> </span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Tree =</span> <span class="fu">as.numeric</span>(Tree)) <span class="sc">%&gt;%</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>()</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_tensor</span>(orange_) <span class="sc">%&gt;%</span> <span class="fu">print</span>(<span class="at">n =</span> <span class="dv">7</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
    2   118    30
    2   484    58
    2   664    87
    2  1004   115
    2  1231   120
    2  1372   142
    2  1582   145
... [the output was truncated (use n=-1 to disable)]
[ CPUFloatType{35,3} ]</code></pre>
<p>Let’s try the same thing with another <code>data.frame</code>, <code>okc</code> from <code>modeldata</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(modeldata)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(okc)</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>okc <span class="sc">%&gt;%</span> <span class="fu">glimpse</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>Rows: 59,855
Columns: 6
$ age      &lt;int&gt; 22, 35, 38, 23, 29, 29, 32, 31, 24,...
$ diet     &lt;chr&gt; "strictly anything", "mostly other",...
$ height   &lt;int&gt; 75, 70, 68, 71, 66, 67, 65, 65, 67, 65,...
$ location &lt;chr&gt; "south san francisco", "oakland",... 
$ date     &lt;date&gt; 2012-06-28, 2012-06-29, 2012-06-27,...
$ Class    &lt;fct&gt; other, other, other, other, other, stem,...</code></pre>
<p>We have two integer columns, which is fine, and one factor column, which we know how to handle. But what about the <code>character</code> and <code>date</code> columns? Trying to create a tensor from the <code>date</code> column individually, we see:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">torch_tensor</span>(okc<span class="sc">$</span>date), <span class="at">n =</span> <span class="dv">7</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 15519
 15520
 15518
 15519
 15518
 15520
 15516
... [the output was truncated (use n=-1 to disable)]
[ CPUFloatType{59855} ]</code></pre>
<p>This didn’t throw an error, but what does it mean? These are the actual values stored in an R <code>Date</code>, namely, the number of days since January 1, 1970. Technically, thus, we have a working conversion – whether the result makes sense pragmatically is a question of how you’re going to use it. Put differently, you’ll probably want to further process these data before using them in a computation, and how you do this will depend on the context.</p>
<p>Next, let’s see about <code>location</code>, one of the columns of type <code>character</code>. What happens if we just pass it to <code>torch</code> as-is?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_tensor</span>(okc<span class="sc">$</span>location)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>Error in torch_tensor_cpp(data, dtype, device, requires_grad,
pin_memory) : R type not handled</code></pre>
<p>In fact, there are no tensors in <code>torch</code> that store strings. We have to apply some scheme that converts them to a numeric type first. In cases like the present one, where every observation contains a single entity (as opposed to, say, a sentence or a paragraph), the easiest way of doing this from R is to first convert to <code>factor</code>, then to <code>numeric</code>, and then, to <code>tensor</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>okc<span class="sc">$</span>location <span class="sc">%&gt;%</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">factor</span>() <span class="sc">%&gt;%</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.numeric</span>() <span class="sc">%&gt;%</span></span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">torch_tensor</span>() <span class="sc">%&gt;%</span></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="at">n =</span> <span class="dv">7</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 120
  74
 102
  10
 102
 102
 102
... [the output was truncated (use n=-1 to disable)]
[ CPUFloatType{59855} ]</code></pre>
<p>True, this works well technically. It <em>does</em>, however, reduce information. For example, the first and third locations are “south san francisco” and “san francisco”, respectively. Once converted to factors, these are just as distant, semantically, as are “san francisco” and any other location. Again, whether this is of relevance depends on the specifics of the data, as well as your goal. If you think it does matter, you have a range of options, including, for example, grouping observations by some criterion, or converting to latitude/longitude. These considerations are by no means <code>torch</code>-specific; we just mention them here because they affect the “data ingestion workflow” to <code>torch</code>.</p>
<p>Finally, no excursion into the world of real-life data science is complete without a consideration of <code>NA</code>s. Let’s see:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_tensor</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="cn">NA</span>, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 1
nan
 3
[ CPUFloatType{3} ]</code></pre>
<p>R’s <code>NA</code> gets converted to <code>NaN</code>. Can you work with that? Some <code>torch</code> function can. For example, <code>torch_nanquantile()</code> just ignores the <code>NaN</code>s:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_nanquantile</span>(<span class="fu">torch_tensor</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="cn">NA</span>, <span class="dv">3</span>)), <span class="at">q =</span> <span class="fl">0.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 2
[ CPUFloatType{1} ]</code></pre>
<p>However, if you’re going to train a neural network, for example, you’ll need to think about how to meaningfully replace these missing values first. But that’s a topic for a later time.</p>
</section>
</section>
<section id="operations-on-tensors" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="operations-on-tensors"><span class="header-section-number">3.3</span> Operations on tensors</h2>
<p>We can perform all the usual mathematical operations on tensors.: add, subtract, divide … These operations are available as functions (starting with <code>torch_</code>) as well as as methods on objects (invoked with <code>$</code>-syntax). For example, the following are equivalent:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">4</span>))</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_add</span>(t1, t2)</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a><span class="co"># equivalently</span></span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span><span class="fu">add</span>(t2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 4
 6
[ CPUFloatType{2} ]</code></pre>
<p>In both cases, a new object is created; neither <code>t1</code> nor <code>t2</code> are modified. There exists an alternate method that modifies its object in-place:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span><span class="fu">add_</span>(t2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 4
 6
[ CPUFloatType{2} ]</code></pre>
<div class="cell">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>t1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 4
 6
[ CPUFloatType{2} ]</code></pre>
<p>In fact, the same pattern applies for other operations: Whenever you see an underscore appended, the object is modified in-place.</p>
<p>Naturally, in a scientific-computing setting, matrix operations are of special interest. Let’s start with the dot product of two one-dimensional structures, i.e., vectors.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="dv">4</span><span class="sc">:</span><span class="dv">6</span>)</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span><span class="fu">dot</span>(t2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
32
[ CPULongType{} ]</code></pre>
<p>Were you thinking this shouldn’t work? Should we have needed to transpose (<code>torch_t()</code>) one of the tensors? In fact, this also works:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>t1<span class="sc">$</span><span class="fu">t</span>()<span class="sc">$</span><span class="fu">dot</span>(t2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
32
[ CPULongType{} ]</code></pre>
<p>The reason the first call worked, too, is that <code>torch</code> does not distinguish between row vectors and column vectors. In consequence, if we multiply a vector with a matrix, using <code>torch_matmul()</code>, we don’t need to worry about the vector’s orientation either:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>t3 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>, <span class="at">ncol =</span> <span class="dv">3</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>))</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>t3<span class="sc">$</span><span class="fu">matmul</span>(t1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 14
 32
 50
 68
[ CPULongType{4} ]</code></pre>
<p>The same function, <code>torch_matmul()</code>, would be used to multiply two matrices. Note how this is different from what <code>torch_multiply()</code> does, namely, scalar-multiply its arguments:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_multiply</span>(t1, t2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
  4
 10
 18
[ CPULongType{3} ]</code></pre>
<p>Many more tensor operations exist, some of which you’ll meet over the course of this journey. But there is one group that deserves special mention.</p>
<section id="summary-operations" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="summary-operations"><span class="header-section-number">3.3.1</span> Summary operations</h3>
<p>If you have an R matrix and are about to compute a sum, this could, normally, mean one of three things: the global sum, row sums, or column sums. Let’s see all three of them at work (using <code>apply()</code> for a reason):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">outer</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>)</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(m)</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a><span class="fu">apply</span>(m, <span class="dv">1</span>, sum)</span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a><span class="fu">apply</span>(m, <span class="dv">2</span>, sum)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 126
[1]  21 42 63
[1]   6 12 18 24 30 36</code></pre>
<p>And now, the <code>torch</code> equivalents. We start with the overall sum.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_outer</span>(<span class="fu">torch_tensor</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>), <span class="fu">torch_tensor</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>))</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span><span class="fu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
126
[ CPULongType{} ]</code></pre>
<p>It gets more interesting for the row and column sums. The <code>dim</code> argument tells <code>torch</code> which dimension(s) to sum over. Passing in <code>dim = 1</code>, we see:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span><span class="fu">sum</span>(<span class="at">dim =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
  6
 12
 18
 24
 30
 36
[ CPULongType{6} ]</code></pre>
<p>Unexpectedly, these are the column sums! Before drawing conclusions, let’s check what happens with <code>dim = 2</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span><span class="fu">sum</span>(<span class="at">dim =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 21
 42
 63
[ CPULongType{3} ]</code></pre>
<p>Now, we have sums over rows. Did we misunderstand something about how <code>torch</code> orders dimensions? No, it’s not that. In <code>torch</code>, when we’re in two dimensions, we think rows first, columns second. (And as you’ll see in a minute, we start indexing with 1, just as in R in general.)</p>
<p>Instead, the conceptual difference is specific to aggregating, or “grouping”, operations. In R, <em>grouping</em>, in fact, nicely characterizes what we have in mind: We group by row (dimension 1) for row summaries, by column (dimension 2) for column summaries. In <code>torch</code>, the thinking is different: We <em>collapse</em> the columns (dimension 2) to compute row summaries, the rows (dimension 1) for column summaries.</p>
<p>The same thinking applies in higher dimensions. Assume, for example, that we been recording time series data for four individuals. There are two features, and both of them have been measured at three times. If we were planning to train a recurrent neural network (much more on that later), we would arrange the measurements like so:</p>
<ul>
<li><p>Dimension 1: Runs over individuals.</p></li>
<li><p>Dimension 2: Runs over points in time.</p></li>
<li><p>Dimension 3: Runs over features.</p></li>
</ul>
<p>The tensor then would look like this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>t</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
(1,.,.) = 
 -1.3427  1.1303
  1.0430  0.8232
  0.7952 -0.2447

(2,.,.) = 
 -1.9929  0.1251
  0.4143  0.3523
  0.9819  0.3219

(3,.,.) = 
  0.6389 -0.2606
  2.4011  0.2656
 -0.1750 -0.2597

(4,.,.) = 
  1.4534  0.7229
  1.2503 -0.2975
  1.6749 -1.2154
[ CPUFloatType{4,3,2} ]</code></pre>
<p>To obtain feature averages, independently of subject and time, we would collapse dimensions 1 and 2:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span><span class="fu">mean</span>(<span class="at">dim =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
-0.1600
 0.1363
[ CPUFloatType{2} ]</code></pre>
<p>If, on the other hand, we wanted feature averages, but individually per person, we’d do:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span><span class="fu">mean</span>(<span class="at">dim =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
-0.6153  0.8290
 0.3961  0.2739
-0.0579  0.1966
-0.3628 -0.7544
[ CPUFloatType{4,2} ]</code></pre>
<p>Here, the single feature “collapsed” is the time step.</p>
</section>
</section>
<section id="accessing-parts-of-a-tensor" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="accessing-parts-of-a-tensor"><span class="header-section-number">3.4</span> Accessing parts of a tensor </h2>
<p>Often, when working with tensors, some computational step is meant to operate on just part of its input tensor. When that part is a single entity (value, row, column …), we commonly refer to this as <em>indexing</em>; when it’s a range of such entities, it is called <em>slicing</em>.</p>
<section id="think-r" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="think-r"><span class="header-section-number">3.4.1</span> “Think R”</h3>
<p>Both indexing and slicing work essentially as in R. There are a few syntactic extensions, and I’ll present these in the subsequent section. But overall you should find the behavior intuitive.</p>
<p>This is because just as in R, indexing in <code>torch</code> is one-based. And just as in R, singleton dimensions are dropped.</p>
<p>In the below example, we ask for the first column of a two-dimensional tensor; the result is one-dimensional, i.e., a vector:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>, <span class="at">ncol =</span> <span class="dv">3</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>))</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>t[<span class="dv">1</span>, ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 1
 2
 3
[ CPULongType{3} ]</code></pre>
<p>If we specify <code>drop = FALSE,</code> though, dimensionality is preserved:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>t[<span class="dv">1</span>, , drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 1  2  3
[ CPULongType{1,3} ]</code></pre>
<p>When slicing, there are no singleton dimensions – and thus, no additional considerations to be taken into account:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_rand</span>(<span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>t[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>, <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
(1,.,.) = 
  0.5273  0.3781
  0.5303  0.9537

(2,.,.) = 
  0.2966  0.7160
  0.5421  0.4284
[ CPUFloatType{2,2,2} ]</code></pre>
<p>In sum, thus, indexing and slicing work very much like in R. Now, let’s look at the aforementioned extensions that further enhance usability.</p>
<section id="beyond-r" class="level4" data-number="3.4.1.1">
<h4 data-number="3.4.1.1" class="anchored" data-anchor-id="beyond-r"><span class="header-section-number">3.4.1.1</span> Beyond R</h4>
<p>One of these extensions concerns accessing the last element in a tensor. Conveniently, in <code>torch</code>, we can use <code>-1</code> to accomplish that:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>))</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>t[<span class="sc">-</span><span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
4
[ CPULongType{} ]</code></pre>
<p>Note how in R, negative indices have a quite different effect, causing elements at respective positions to be removed.</p>
<p>Another useful feature extends slicing syntax to allow for a step pattern, to be specified after a second colon. Here, we request values from every second column between columns one and eight:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">ncol =</span> <span class="dv">10</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>))</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>t[ , <span class="dv">1</span><span class="sc">:</span><span class="dv">8</span><span class="sc">:</span><span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
  1   3   5   7
 11  13  15  17
[ CPULongType{2,4} ]</code></pre>
<p>Finally, sometimes the same code should be able to work with tensors of different dimensionalities. In this case, we can use <code>..</code> to collectively designate any existing dimensions not explicitly referenced.</p>
<p>For example, say we want to index into the first dimension of whatever tensor is passed, be it a matrix, an array, or some higher-dimensional structure. The following</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>t[<span class="dv">1</span>, ..]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>will work for all:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>t3 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>t1[<span class="dv">1</span>, ..]</span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a>t2[<span class="dv">1</span>, ..]</span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a>t3[<span class="dv">1</span>, ..]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
-0.6179
-1.4769
[ CPUFloatType{2} ]


torch_tensor
 1.0602 -0.9028
 0.2942  0.4611
[ CPUFloatType{2,2} ]


torch_tensor
(1,.,.) = 
  1.3304 -0.6018
  0.0825  0.1221

(2,.,.) = 
  1.7129  1.2932
  0.2371  0.9041
[ CPUFloatType{2,2,2} ]</code></pre>
<p>If we wanted to index into the last dimension instead, we’d write <code>t[.., 1]</code>. We can even combine both:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>t3[<span class="dv">1</span>, .., <span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
-0.6018  0.1221
 1.2932  0.9041
[ CPUFloatType{2,2} ]</code></pre>
<p>Now, a topic just as important as indexing and slicing is reshaping of tensors.</p>
</section>
</section>
</section>
<section id="reshaping-tensors" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="reshaping-tensors"><span class="header-section-number">3.5</span> Reshaping tensors</h2>
<p>Say you have a tensor with twenty-four elements. What is its shape? It could be any of the following:</p>
<ul>
<li><p>a vector of length 24</p></li>
<li><p>a matrix of shape 24 x 1, or 12 x 2, or 6 x 4, or …</p></li>
<li><p>a three-dimensional array of size 24 x 1 x 1, or 12 x 2 x 1, or …</p></li>
<li><p>and so on (in fact, it could even have shape 24 x 1 x 1 x 1 x 1)</p></li>
</ul>
<p>We can modify a tensor’s shape, without juggling around its values, using the <code>view()</code> method. Here is the initial tensor, a vector of length 24:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_zeros</span>(<span class="dv">24</span>)</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(t, <span class="at">n =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 0
 0
 0
... [the output was truncated (use n=-1 to disable)]
[ CPUFloatType{24} ]</code></pre>
<p>Here is that same vector, reshaped to a wide matrix:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> t<span class="sc">$</span><span class="fu">view</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">12</span>))</span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>t2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 0  0  0  0  0  0  0  0  0  0  0  0
 0  0  0  0  0  0  0  0  0  0  0  0
[ CPUFloatType{2,12} ]</code></pre>
<p>So we have a new tensor, <code>t2</code>, but interestingly (and importantly, performance-wise), <code>torch</code> did not have to allocate any new storage for its values. This we can verify for ourselves. Both tensors store their data in the same location:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span><span class="fu">storage</span>()<span class="sc">$</span><span class="fu">data_ptr</span>()</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>t2<span class="sc">$</span><span class="fu">storage</span>()<span class="sc">$</span><span class="fu">data_ptr</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] "0x55cd15789180"
[1] "0x55cd15789180"</code></pre>
<p>Let’s talk a bit about how this is possible.</p>
<section id="zero-copy-reshaping-vs.-reshaping-with-copy" class="level3" data-number="3.5.1">
<h3 data-number="3.5.1" class="anchored" data-anchor-id="zero-copy-reshaping-vs.-reshaping-with-copy"><span class="header-section-number">3.5.1</span> Zero-copy reshaping vs.&nbsp;reshaping with copy</h3>
<p>Whenever we ask <code>torch</code> to perform an operation that changes the shape of a tensor, it tries to fulfill the request without allocating new storage for the tensor’s contents. This is possible because the same data – the same bytes, ultimately – can be read in different ways. All that is needed is storage for the <em>metadata</em>.</p>
<p>How does <code>torch</code> do it? Let’s see a concrete example. We start with a 3 x 5 matrix.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(<span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>, <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>))</span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>t</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code> torch_tensor
  1   2   3   4   5
  6   7   8   9  10
 11  12  13  14  15
[ CPULongType{3,5} ]</code></pre>
<p>Tensors have a <code>stride()</code> method that tracks, <em>for every dimension</em>, how many elements have to be traversed to arrive at its next element. For the above tensor <code>t</code>, to go to the next row, we have to skip over five elements, while to go to the next column, we need to skip just one:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span><span class="fu">stride</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 5 1</code></pre>
<p>Now we reshape the tensor so it has five rows and three columns instead. Remember, the data themselves do not change.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> t<span class="sc">$</span><span class="fu">view</span>(<span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">3</span>))</span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>t2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
  1   2   3
  4   5   6
  7   8   9
 10  11  12
 13  14  15
[ CPULongType{5,3} ]</code></pre>
<p>This time, to arrive at the next row, we just skip three elements instead of five. To get to the next column, we still just “jump over” a single element only:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>t2<span class="sc">$</span><span class="fu">stride</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 3 1</code></pre>
<p>Now you may be thinking, what if the order of the elements also has to change? For example, in matrix transposition. Is that still doable with the metadata-only approach?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>t3 <span class="ot">&lt;-</span> t<span class="sc">$</span><span class="fu">t</span>()</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>t3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
  1   6  11
  2   7  12
  3   8  13
  4   9  14
  5  10  15
[ CPULongType{5,3} ]</code></pre>
<p>In fact, it must be, as both the original tensor and its transpose point to the same place in memory:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span><span class="fu">storage</span>()<span class="sc">$</span><span class="fu">data_ptr</span>()</span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a>t3<span class="sc">$</span><span class="fu">storage</span>()<span class="sc">$</span><span class="fu">data_ptr</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] "0x55cd1cd4a840"
[1] "0x55cd1cd4a840"</code></pre>
<p>And it makes sense: This will work if we know that to arrive at the next row, we just skip a single element, while to arrive at the next column, that’s five to skip over now. Let’s verify:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>t3<span class="sc">$</span><span class="fu">stride</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 1 5</code></pre>
<p>Exactly.</p>
<p>Whenever possible, <code>torch</code> will try to handle shape-changing operations in this way.</p>
<p>Another such <em>zero-copy</em> operation (and one we’ll see a lot) is <code>squeeze()</code>, together with its antagonist, <code>unsqueeze()</code>. The latter adds a singleton dimension at the requested position, the former removes it. For example:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="dv">3</span>)</span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a>t</span>
<span id="cb132-3"><a href="#cb132-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb132-4"><a href="#cb132-4" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span><span class="fu">unsqueeze</span>(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
 0.2291
-0.9454
 1.6630
[ CPUFloatType{3} ]

torch_tensor
 0.2291 -0.9454  1.6630
[ CPUFloatType{1,3} ]</code></pre>
<p>Here we added a singleton dimension in front. Alternatively, we could have used <code>t$unsqueeze(2)</code> to add it at the end.</p>
<p>Now, will that zero-copy technique ever fail? Here is an example where it does:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span><span class="fu">t</span>()<span class="sc">$</span><span class="fu">view</span>(<span class="dv">9</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code> Error in (function (self, size)  : 
  view size is not compatible with input tensor's size and
  stride (at least one dimension spans across two contiguous
  subspaces). Use .reshape(...) instead. [...]</code></pre>
<p>When two operations that change the stride are executed in sequence, the second is pretty likely to fail. There is a way to exactly determine whether it will fail or not; but the easiest way is to just use a different method instead of <code>view()</code>: <code>reshape()</code>. The latter will “automagically” work metadata-only if that is possible, but make a copy if not:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> t<span class="sc">$</span><span class="fu">t</span>()<span class="sc">$</span><span class="fu">reshape</span>(<span class="dv">9</span>)</span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span><span class="fu">storage</span>()<span class="sc">$</span><span class="fu">data_ptr</span>()</span>
<span id="cb136-5"><a href="#cb136-5" aria-hidden="true" tabindex="-1"></a>t2<span class="sc">$</span><span class="fu">storage</span>()<span class="sc">$</span><span class="fu">data_ptr</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] "0x55cd1622a000"
[1] "0x55cd19d31e40"</code></pre>
<p>As expected, both tensors are now stored in different locations.</p>
<p>Finally, we are going to end this long chapter with a feature that may seem overwhelming at first, but is of tremendous importance performance-wise. Like with so many things, it takes time to get accustomed to, but rest assured: You’ll encounter it again and again, in this book and in many projects using <code>torch</code>. It is called <em>broadcasting</em>.</p>
</section>
</section>
<section id="broadcasting" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="broadcasting"><span class="header-section-number">3.6</span> Broadcasting</h2>
<p>We often have to perform operations on tensors with shapes that don’t match exactly.</p>
<p>Of course, we wouldn’t probably try to add, say, a length-two vector to a length-five vector. But there are things we <em>may</em> want to do: for example, multiply every element by a scalar. This works:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="ot">&lt;-</span> <span class="fu">torch_randn</span>(<span class="dv">3</span>, <span class="dv">5</span>)</span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>t1 <span class="sc">*</span> <span class="fl">0.5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
-0.4845  0.3092 -0.3710  0.3558 -0.2126
-0.3419  0.1160  0.1800 -0.0094 -0.0189
-0.0468 -0.4030 -0.3172 -0.1558 -0.6247
[ CPUFloatType{3,5} ]</code></pre>
<p>That was probably a bit underwhelming. We’re used to that; from R. But the following does not work in R. The intention here would be to add the same vector to every row in a matrix:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>, <span class="at">ncol =</span> <span class="dv">5</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="at">ncol =</span> <span class="dv">5</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-4"><a href="#cb140-4" aria-hidden="true" tabindex="-1"></a>m <span class="sc">+</span> m2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>Error in m + m2 : non-conformable arrays</code></pre>
<p>Neither does it help if we make <code>m2</code> a vector.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>m3 <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span></span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a>m <span class="sc">+</span> m3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>     [,1] [,2] [,3] [,4] [,5]
[1,]    2    6    5    9    8
[2,]    8   12   11   10   14
[3,]   14   13   17   16   20</code></pre>
<p>Syntactically this worked, but semantics-wise this is not what we intended.</p>
<p>Now, we try both of the above with <code>torch</code>. First, again, the scenario where both tensors are two-dimensional (even though, conceptually, one of them is a row vector):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(m)</span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a>t2 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(m2)</span>
<span id="cb144-3"><a href="#cb144-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb144-4"><a href="#cb144-4" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span>shape</span>
<span id="cb144-5"><a href="#cb144-5" aria-hidden="true" tabindex="-1"></a>t2<span class="sc">$</span>shape</span>
<span id="cb144-6"><a href="#cb144-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb144-7"><a href="#cb144-7" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span><span class="fu">add</span>(t2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>[1] 3 5</p>
<p>[1] 1 5</p>
<pre><code>torch_tensor
  2   4   6   8  10
  7   9  11  13  15
 12  14  16  18  20
[ CPULongType{3,5} ]</code></pre>
<p>And now, with the thing to be added a one-dimensional tensor:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>t3 <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>(m3)</span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-3"><a href="#cb146-3" aria-hidden="true" tabindex="-1"></a>t3<span class="sc">$</span>shape</span>
<span id="cb146-4"><a href="#cb146-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-5"><a href="#cb146-5" aria-hidden="true" tabindex="-1"></a>t<span class="sc">$</span><span class="fu">add</span>(t3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 5
torch_tensor
  2   4   6   8  10
  7   9  11  13  15
 12  14  16  18  20
[ CPULongType{3,5} ]</code></pre>
<p>In <code>torch</code>, both ways worked as intended. Let’s see why.</p>
<p>Above, I’ve printed the tensor shapes for a reason. To a tensor of shape 3 x 5, we were able to add both a tensor of shape 3 and a tensor of shape 1 x 5. Together, these illustrate how broadcasting works. In a nutshell, this is what happens:</p>
<ol type="1">
<li><p>The 1 x 5 tensor, when used as an addend, is virtually expanded, that is, treated as if it contained the same row three times. This kind of expansion can only be performed if the non-matching dimension is a singleton, and if it is located on the left.</p></li>
<li><p>The same thing happens to the shape-3 tensor, but there is one additional step that takes place first: A leading dimension of size 1 is – virtually – appended on the left. This puts us in exactly the same state we were in in (1), and we continue from there.</p></li>
</ol>
<p>Importantly, no physical expansions take place.</p>
<p>Let’s systematize these rules.</p>
<section id="broadcasting-rules" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="broadcasting-rules"><span class="header-section-number">3.6.1</span> Broadcasting rules</h3>
<p>The rules are the following. The first, unspectactular though it may look, is the basis for everything else.</p>
<ol type="1">
<li>We align tensor shapes, <em>starting from the right</em>.</li>
</ol>
<p>Say we have two tensors, one of size 3 x 7 x 1, the other of size 1 x 5. Here they are, right-aligned:</p>
<pre><code># t1, shape:        3  7  1
# t2, shape:           1  5</code></pre>
<ol start="2" type="1">
<li><em>Starting from the right</em>, the sizes along aligned axes either have to match exactly, or one of them has to be equal to 1. In the latter case, the singleton-dimension tensor is <em>broadcast</em> to the non-singleton one.</li>
</ol>
<p>In the above example, broadcasting happens twice – once for each tensor. This (virtually) yields</p>
<pre><code># t1, shape:        3  7  5
# t2, shape:           7  5</code></pre>
<ol start="3" type="1">
<li>If, on the left, one of the tensors has an additional axis (or more than one), the other is virtually expanded to have a dimension of size 1 in that place, in which case broadcasting will occur as stated in (2).</li>
</ol>
<p>In our example, this happens to the second tensor. First, there is a virtual expansion</p>
<pre><code># t1, shape:        3  7  5
# t2, shape:        1  7  5</code></pre>
<p>and then, broadcasting takes place:</p>
<pre><code># t1, shape:        3  7  5
# t2, shape:        3  7  5</code></pre>
<p>In this example, we see that broadcasting can act on both tensors at the same time. The thing to keep in mind, though, is that we always start looking from the right. For example, no broadcasting in the world could make <em>this</em> work:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="fu">torch_zeros</span>(<span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>)<span class="sc">$</span><span class="fu">add</span>(<span class="fu">torch_ones</span>(<span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>)) <span class="co"># error!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p>Now, that was one of the longest, and least applied-seeming, perhaps, chapters in the book. But feeling comfortable with tensors is, I dare say, a precondition for being fluent in <code>torch</code>. The same goes for the topic covered in the next chapter, automatic differentiation. But the difference is, there <code>torch</code> does <em>all</em> the heavy lifting for us. We just need to understand what it’s doing.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./what_is_torch.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">On <code>torch</code>, and how to get it</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./autograd.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Autograd</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>