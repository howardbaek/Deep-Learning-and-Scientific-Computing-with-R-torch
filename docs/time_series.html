<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-99.9.9">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Deep Learning and Scientific Computing with R torch - 21&nbsp; Time series</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./audio_classification.html" rel="next">
<link href="./tabular_data.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./dl_overview.html">Deep learning with torch</a></li><li class="breadcrumb-item"><a href="./time_series.html"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Time series</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Deep Learning and Scientific Computing with R torch</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Getting familiar with torch</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./basics_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Overview</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./what_is_torch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">On <code>torch</code>, and how to get it</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tensors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Tensors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./autograd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Autograd</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./optim_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Function minimization with <em>autograd</em></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./network_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">A neural network from scratch</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./modules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Modules</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./optimizers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Optimizers</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./loss_functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Loss functions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./optim_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Function minimization with L-BFGS</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./network_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Modularizing the neural network</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Deep learning with torch</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dl_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Overview</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Loading data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./training_with_luz.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Training with luz</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./image_classification_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">A first go at image classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./overfitting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Making models generalize</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./training_efficiency.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Speeding up training</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./image_classification_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Image classification, take two: Improving performance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./image_segmentation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Image segmentation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tabular_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Tabular data</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./time_series.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Time series</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./audio_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Audio classification</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Other things to do with torch: Matrices, Fourier Transform, and Wavelets</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./other_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Overview</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./matrix_computations_leastsquares.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Matrix computations: Least-squares problems</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./matrix_computations_convolution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Matrix computations: Convolution</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fourier_transform_dft.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Exploring the Discrete Fourier Transform (DFT)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fourier_transform_fft.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">The Fast Fourier Transform (FFT)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wavelets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Wavelets</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#deep-learning-for-sequences-the-idea" id="toc-deep-learning-for-sequences-the-idea" class="nav-link active" data-scroll-target="#deep-learning-for-sequences-the-idea"><span class="header-section-number">21.1</span> Deep learning for sequences: the idea</a></li>
  <li><a href="#a-basic-recurrent-neural-network" id="toc-a-basic-recurrent-neural-network" class="nav-link" data-scroll-target="#a-basic-recurrent-neural-network"><span class="header-section-number">21.2</span> A basic recurrent neural network</a>
  <ul class="collapse">
  <li><a href="#basic-rnn_cell" id="toc-basic-rnn_cell" class="nav-link" data-scroll-target="#basic-rnn_cell"><span class="header-section-number">21.2.1</span> Basic <code>rnn_cell()</code></a></li>
  <li><a href="#basic-rnn_module" id="toc-basic-rnn_module" class="nav-link" data-scroll-target="#basic-rnn_module"><span class="header-section-number">21.2.2</span> Basic <code>rnn_module()</code></a></li>
  </ul></li>
  <li><a href="#recurrent-neural-networks-in-torch" id="toc-recurrent-neural-networks-in-torch" class="nav-link" data-scroll-target="#recurrent-neural-networks-in-torch"><span class="header-section-number">21.3</span> Recurrent neural networks in <code>torch</code></a></li>
  <li><a href="#rnns-in-practice-gru-and-lstm" id="toc-rnns-in-practice-gru-and-lstm" class="nav-link" data-scroll-target="#rnns-in-practice-gru-and-lstm"><span class="header-section-number">21.4</span> RNNs in practice: GRU and LSTM</a></li>
  <li><a href="#forecasting-electricity-demand" id="toc-forecasting-electricity-demand" class="nav-link" data-scroll-target="#forecasting-electricity-demand"><span class="header-section-number">21.5</span> Forecasting electricity demand</a>
  <ul class="collapse">
  <li><a href="#data-inspection" id="toc-data-inspection" class="nav-link" data-scroll-target="#data-inspection"><span class="header-section-number">21.5.1</span> Data inspection</a></li>
  <li><a href="#forecasting-the-very-next-value" id="toc-forecasting-the-very-next-value" class="nav-link" data-scroll-target="#forecasting-the-very-next-value"><span class="header-section-number">21.5.2</span> Forecasting the very next value</a></li>
  <li><a href="#forecasting-multiple-time-steps-ahead" id="toc-forecasting-multiple-time-steps-ahead" class="nav-link" data-scroll-target="#forecasting-multiple-time-steps-ahead"><span class="header-section-number">21.5.3</span> Forecasting multiple time steps ahead</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec:time-series" class="quarto-section-identifier"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Time series</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>In this chapter, we’ll again look at a new type of data: time series. Previously, moving on from images to tabular data, we found a substantial difference in that image data are homogeneous, while tabular data aren’t. With images, individual values correspond to pixels, or positions on a grid. With tabular data, values can – in principle – be “anything”; but most often, we deal with a mix of categorical, ordinal, and numerical data. However, both types of application have one thing in common: All values relate to the same point in time.</p>
<p>With time series, we’re facing a new situation. Assume the series is one-dimensional, that is, it has a single feature. Thus, the data type is homogeneous. But now, the input is a sequence. What follows?</p>
<p>Before, when a mix of data types were present, we found we had to do some pre-processing up-front. We also saw that, by adding in a new type of module - the embedding module – we could refine and enhance the overall (linear) model. Now though, a bigger change is needed. We again will have to do some pre-processing; but this time, we’ll also need a different type of top-level <em>model</em>, a type as different from the standard feed-forward architecture as is the convolutional one we already studied.</p>
<section id="deep-learning-for-sequences-the-idea" class="level2" data-number="21.1">
<h2 data-number="21.1" class="anchored" data-anchor-id="deep-learning-for-sequences-the-idea"><span class="header-section-number">21.1</span> Deep learning for sequences: the idea</h2>
<p>Say we have a sequence of daily average temperatures, measured in degrees Celsius: <code>-1.1, 2.0, -0.2, -0.9, 4.5, -3.6, -9.1</code>. Clearly, these values are not independent; we’d hardly guess that the very next measurement would result in in, say, <code>21</code>. In fact, if these seven averages were all you’re given, your best guess for the next day would probably just be <code>-9.1</code>. But when people say “time series”, they have longer sequences in mind. With longer sequences, you can try to detect patterns, such as trends or periodicities. And that’s what the established techniques in time series analysis do.</p>
<p>For a deep learning model to do the same, it first of all has to “perceive” individual values as sequential. We make that happen by increasing tensor dimensionality by one, and using the additional dimension for sequential ordering. Now, the model has to do something useful with that. Think back of what it is a linear model is doing: It takes input <span class="math inline">\(\mathbf{X}\)</span>, multiplies by its weight matrix <span class="math inline">\(\mathbf{W}\)</span>, and adds bias vector <span class="math inline">\(\mathbf{b}\)</span>:</p>
<p><span class="math display">\[
f(\mathbf{X}) = \mathbf{X}\mathbf{W} + \mathbf{b}
\]</span></p>
<p>In sequence models, this type of operation is still present; it’s just that now, it is executed for every time step – i.e., every position in the sequence – in isolation. But this means that now, the relationship <em>between time steps</em> has to be taken care of. To that end, the module takes what was obtained at the previous time step, applies a different weight matrix, and adds a different bias vector. This, in itself, is again an affine transformation, – just not of the input, but of what is called the previous <em>state</em>. The outputs from both affine computations are added, and the result then serves as prior state to the computation due at the next time step.</p>
<p>In other words, <em>at each time step</em>, two types of information are combined: the (weight-transformed) input for the current time step, and the (weight-transformed) state that resulted from processing the previous one. In math:</p>
<p><span class="math display">\[
state_{(t)} = f(\mathbf{W_{input}}\mathbf{X_{(t)}} + \mathbf{b_{input}} + \mathbf{W_{state}}\mathbf{X_{(t-1)}} + \mathbf{b_{state}})
\]</span></p>
<p>This logic specifies a <em>recurrence relation</em>, and modules implementing it are called <em>recurrent neural networks</em> (RNNs). In the next section, we’ll implement such a module ourselves; you’ll see how, in code, that recurrence maps to straightforward iteration. Before, two remarks.</p>
<p>First, in the above formula, the function applied to the sum of the two transformations represents an activation; typically for RNNs, the default is the hyperbolic tangent, <code>torch_tanh()</code>.</p>
<p>Second, in the official <code>torch</code> documentation, you’ll see the formula written this way:</p>
<p><span class="math display">\[
h_{(t)} = f(\mathbf{W_{i\_h}\mathbf{X_{(t)}} }+ \mathbf{b_{i\_h}} + \mathbf{W_{h\_h}\mathbf{X}_{(t-1)}} + \mathbf{b}_{h\_h})
\]</span></p>
<p>Here <span class="math inline">\(h\)</span> stands for “hidden”, as in “hidden state”, and subscripts <span class="math inline">\(i\_h\)</span> and <span class="math inline">\(h\_h\)</span> stand for “input-to-hidden” and “hidden-to-hidden”, respectively. The reason I’d like to de-emphasize the “hidden” in “hidden state” is because in the <code>torch</code> implementation, the state is not necessarily hidden from the user. You’ll see what I mean below. (Pretty soon, I’ll give up resistance against the term, though, since it is ubiquitous in descriptive prose as well as code (for example, as regards variable naming). But I wanted to state this clearly at least once, so you won’t be confused when mapping your mental model of the algorithm to the behavior of <code>torch</code> RNNs.</p>
</section>
<section id="a-basic-recurrent-neural-network" class="level2" data-number="21.2">
<h2 data-number="21.2" class="anchored" data-anchor-id="a-basic-recurrent-neural-network"><span class="header-section-number">21.2</span> A basic recurrent neural network</h2>
<p>In the above discussion, we identified two basic things a recurrent neural network has to do: (1) iterate over the input sequence; and (2) execute the “business logic” of a sequence, that is, combine information from the previous as well as the current time step.</p>
<p>Commonly, these duties are divided between two different objects. One, referred to as the “cell”, implements the logic. The other takes care of the iteration. The reason for this modularization is that both “inner” and “outer” logic should be modifiable independently. For example, you might want to keep the way you iterate over time steps, but modify what happens at each point in the iteration. This will get more concrete later, when we talk about the most-used sub-types of RNNs.</p>
<p>In our basic implementation of a basic RNN, both cell and iteration handler are <code>nn_module()</code>s. First, we have the <em>cell</em>.</p>
<section id="basic-rnn_cell" class="level3" data-number="21.2.1">
<h3 data-number="21.2.1" class="anchored" data-anchor-id="basic-rnn_cell"><span class="header-section-number">21.2.1</span> Basic <code>rnn_cell()</code></h3>
<p>The logic combines two affine operations; and affine operations are just what linear modules are for. We therefore just have our cell delegate to two linear modules, append the respective outputs, and apply a <em>tanh</em> activation.</p>
<p>As already alluded to above, in naming the modules and parameters, I’m following the <code>torch</code> conventions, so things will sound familiar when we move on to actual <code>torch</code> modules. Most notably, this includes referring to the state as “hidden state”, and thus, to its dimensionality as <code>hidden_size</code>, even though state is hidden from the user only under certain circumstances (which we’ll come to).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(zeallot) <span class="co"># for destructuring using %&lt;-%</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>rnn_cell <span class="ot">&lt;-</span> <span class="fu">nn_module</span>(</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">initialize =</span> <span class="cf">function</span>(input_size, hidden_size) {</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>linear_i_h <span class="ot">&lt;-</span> <span class="fu">nn_linear</span>(input_size, hidden_size)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>linear_h_h <span class="ot">&lt;-</span> <span class="fu">nn_linear</span>(hidden_size, hidden_size)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">forward =</span> <span class="cf">function</span>(x, prev_state) {</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">torch_tanh</span>(self<span class="sc">$</span><span class="fu">linear_i_h</span>(x) <span class="sc">+</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span><span class="fu">linear_h_h</span>(prev_state))</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>From the way the cell has been defined, we see that to instantiate it, we need to pass <code>hidden_size</code> and <code>input_size</code> – the latter referring to the number of features in the dataset. Let’s make those 3 and 1, respectively:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>cell <span class="ot">&lt;-</span> <span class="fu">rnn_cell</span>(<span class="at">input_size =</span> <span class="dv">1</span>, <span class="at">hidden_size =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As a quick test, we call the module on a (tiny) batch of data, passing in the previous (or: initial) state. As in the actual <code>torch</code> implementation, the state is initialized to an all-zeros tensor:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cell</span>(<span class="fu">torch_randn</span>(<span class="dv">2</span>, <span class="dv">1</span>), <span class="fu">torch_zeros</span>(<span class="dv">2</span>, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>torch_tensor
-0.6340  0.9571 -0.9886
-0.3007  0.9201 -0.9689
[ CPUFloatType{2,3} ][ grad_fn = &lt;TanhBackward0&gt; ]</code></pre>
<p>Note the dimensionality of the output. For each batch item, we get the new state, of size <code>hidden_size</code>.</p>
<p>Now, a cell is not normally supposed to be called by the user; instead, we should call the to-be-defined <code>rnn_module()</code>. That module will take care of the iteration, delegating to an instance of <code>rnn_cell()</code> at each step. Let’s implement this one next.</p>
</section>
<section id="basic-rnn_module" class="level3" data-number="21.2.2">
<h3 data-number="21.2.2" class="anchored" data-anchor-id="basic-rnn_module"><span class="header-section-number">21.2.2</span> Basic <code>rnn_module()</code></h3>
<p>Conceptually, this module is easily characterized – it iterates over points in time. But there are a few things to note in the implementation that follows.</p>
<p>First, note that it expects a single argument to <code>forward()</code>, not two – there is no need to pass in an initial state. (In actual <code>torch</code> implementations, the user can pass an initial state to start from, if they want. But if they don’t, the state will start out as all zeros, just like in this prototype.)</p>
<p>Second, and most importantly, let’s talk about the dimensionality of <code>x</code>, the single input argument. Where the cell operates on tensors of size <code>batch_size</code> times <code>num_features</code>, the iteration module expects its input to have an additional dimension, inserted at position two – right “in the middle”. You can see this in the line</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(batch_size, timesteps, num_features) <span class="sc">%&lt;-%</span> x<span class="sc">$</span><span class="fu">size</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This additional dimension is used to capture evolution over time. <code>rnn_module()</code> will iterate over its values, call <code>rnn_cell()</code> for each step in the sequence, and keep track of the outputs:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>timesteps) {</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  new_state <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">cell</span>(x[ , t, ], cur_state)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  states[[t]] <span class="ot">&lt;-</span> new_state</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  cur_state <span class="ot">&lt;-</span> new_state</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As you see, in every call to <code>self$cell</code>, the previous state is passed as well, fulfilling the contract on <code>rnn_cell$forward()</code>.</p>
<p>The complete code for <code>rnn_module()</code> is just slightly longer than that for the cell:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>rnn_module <span class="ot">&lt;-</span> <span class="fu">nn_module</span>(</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">initialize =</span> <span class="cf">function</span>(input_size, hidden_size) {</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>cell <span class="ot">&lt;-</span> <span class="fu">rnn_cell</span>(input_size, hidden_size)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>hidden_size <span class="ot">&lt;-</span> hidden_size</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">forward =</span> <span class="cf">function</span>(x) {</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">c</span>(batch_size, timesteps, num_features) <span class="sc">%&lt;-%</span> x<span class="sc">$</span><span class="fu">size</span>()</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    init_hidden <span class="ot">&lt;-</span> <span class="fu">torch_zeros</span>(batch_size, self<span class="sc">$</span>hidden_size)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    cur_state <span class="ot">&lt;-</span> init_hidden</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># list containing the hidden states</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># (equivalently: outputs), of length timesteps</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    states <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="at">mode =</span> <span class="st">"list"</span>, <span class="at">length =</span> timesteps)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loop over time steps</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>timesteps) {</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>      new_state <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">cell</span>(x[, t, ], cur_state)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>      states[[t]] <span class="ot">&lt;-</span> new_state</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>      cur_state <span class="ot">&lt;-</span> new_state</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># put sequence of states in dimension 2</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    states <span class="ot">&lt;-</span> <span class="fu">torch_stack</span>(states, <span class="at">dim =</span> <span class="dv">2</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">list</span>(states, states[, timesteps, ])</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note how dimension two, the one that, in the input, held the time dimension, now is used to pack the states obtained for each time step. I’ll say more about that in a second, but first, let’s test that module. I’ll stay with a state size (<code>hidden_size</code>) of three, and make our sample input have four consecutive measurements:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="ot">&lt;-</span> <span class="fu">rnn_module</span>(<span class="at">input_size =</span> <span class="dv">1</span>, <span class="at">hidden_size =</span> <span class="dv">3</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>output <span class="ot">&lt;-</span> <span class="fu">rnn</span>(<span class="fu">torch_randn</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>))</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>output</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[[1]]
torch_tensor
(1,.,.) = 
 -0.9066  0.8149 -0.3671
 -0.9772  0.2903 -0.7938
 -0.9724  0.6242 -0.7877
 -0.9811  0.4164 -0.8839

(2,.,.) = 
 -0.8901  0.8795  0.3131
 -0.9512  0.4883  0.4991
 -0.9297  0.4875  0.1878
 -0.9420  0.5741  0.1564
[ CPUFloatType{2,4,3} ][ grad_fn = &lt;StackBackward0&gt; ]

[[2]]
torch_tensor
-0.9811  0.4164 -0.8839
-0.9420  0.5741  0.1564
[ CPUFloatType{2,3} ][ grad_fn = &lt;SliceBackward0&gt; ]</code></pre>
<p>So, <code>rnn_module()</code> returns a list of length two. First in the list is a tensor containing the states at all time steps – for each batch item, and for each unit in the state. At the risk of being redundant, here are its dimensions:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># batch_size, timesteps, hidden_size</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(output[[<span class="dv">1</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 2 4 3</code></pre>
<p>The reason I’m stressing this is that you’ll see the same convention reappear in the actual <code>torch</code> implementation, and the conventions associated with processing time series data can take some time to get accustomed to.</p>
<p>Now, what about the second tensor? It really is a slice of the first – one reflecting the final state only. Correspondingly, its number of dimensions is reduced by one:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># batch_size, hidden_size</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(output[[<span class="dv">2</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 2 3</code></pre>
<p>Now, as users, why would we need that second tensor?</p>
<p>We don’t. We can just do the slicing ourselves. Remember how, above, I first tried to avoid the term “hidden states”, and said I’d rather just talk about “states” instead? This is why: Whether the states <em>really</em> are hidden is up to implementation, that is, <em>developer choice</em>. A framework could decide to return the very last state only, unless the caller explicitly asks for the preceding ones. In that case, it would make sense to talk about “the” output on the one hand, and the sequence of “hidden states”, on the other. We <em>could</em> have coded our sample implementation like that. Instead, we were following <code>torch</code>’s <code>nn_rnn()</code>, which you’ll encounter in a second.</p>
<p>Thus, what I’m saying is: It all is a matter of conventions. But this doesn’t explain <em>why</em> the <code>torch</code> developers chose to return an additional, sliced-to-the-last-time-step, tensor: This clearly seems redundant. Is it?</p>
<p>Well, it often is. <em>Whether</em> it is or not depends, for one, on the type of RNN. If you use <code>torch</code>’s <code>nn_rnn()</code> (a “simple” RNN implementation not much employed in practice) or <code>nn_gru()</code> – creating a default <em>Gated Recurrent Network</em>, one of two “classical”, tried-and-true architectures – it will be. If, on the other hand, you ask <code>torch</code> for a setup where a single RNN module really is a composite of layers, and/or you use an <em>LSTM</em> (<em>Long Short-Term Memory</em> Network, the second “classic”), then one tensor will not be a subset of the other.</p>
<p>At this point, it definitely is time to look at those <code>torch</code> modules.</p>
</section>
</section>
<section id="recurrent-neural-networks-in-torch" class="level2" data-number="21.3">
<h2 data-number="21.3" class="anchored" data-anchor-id="recurrent-neural-networks-in-torch"><span class="header-section-number">21.3</span> Recurrent neural networks in <code>torch</code></h2>
<p>Here, first, is <code>nn_rnn()</code>, a more feature-rich, but similar-in-spirit to our prototype recurrent module. In practice, you’ll basically always use either <code>nn_gru()</code> or <code>nn_lstm()</code>, which is why we won’t spend much time on it. Especially, we don’t talk about optional arguments (yet), with two exceptions.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>rnn <span class="ot">&lt;-</span> <span class="fu">nn_rnn</span>(<span class="at">input_size =</span> <span class="dv">1</span>, </span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>              <span class="at">hidden_size =</span> <span class="dv">3</span>, </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">batch_first =</span> <span class="cn">TRUE</span>,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">num_layers =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Both <code>batch_first</code> and <code>num_layers</code> arguments are optional. The latter, <code>num_layers</code>, allows for creating a stack of RNN modules instead of a single one; this is convenient because the user does not have to worry about how to correctly wire them together. The default, though, is <code>1</code>: exactly what we’re passing in, above. The reason I’m specifying it explicitly is just so you know it exists, and aren’t confused by the module’s output. Namely, you’ll see that the second in the list of tensors returned by <code>rnn$forward()</code> has an additional dimension that indicates the layer.</p>
<p>In contrast, <code>batch_first</code> is not set to its default; and it’s essential to be aware of this. By default, the convention for RNNs differs from those for other modules; if we didn’t pass the argument, <code>torch</code> would expect the first dimension to be representing time steps, not batch items. In this book, we’ll always pass <code>batch_first = TRUE</code>.</p>
<p>Now, calling that RNN on the same test tensor we used in our manual implementation above, and checking the dimensions of the output, we see:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>output <span class="ot">&lt;-</span> <span class="fu">rnn</span>(<span class="fu">torch_randn</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>))</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># output</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(output[[<span class="dv">1</span>]]) <span class="co"># batch_size, timesteps, hidden_size</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># last hidden state (per layer)</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(output[[<span class="dv">2</span>]]) <span class="co"># num_layers, batch_size, hidden_size</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 2 4 3
[1] 1 2 3</code></pre>
<p>The first tensor in the list has a shape that exactly matches what would be returned by our manual implementation.</p>
<p>Semantically, the respective second tensors in the output lists match up as well, in that both of them zoom in on the final state. But <code>torch</code>, allowing for the chaining of several RNNs in a single module, returns the final state <em>per layer</em>. In the <code>torch</code> implementation, is that second tensor redundant? It is, in our example. But were we to create a multi-layer RNN, it would give us information not contained in the first tensor: namely, the last hidden state for each non-final layer.</p>
</section>
<section id="rnns-in-practice-gru-and-lstm" class="level2" data-number="21.4">
<h2 data-number="21.4" class="anchored" data-anchor-id="rnns-in-practice-gru-and-lstm"><span class="header-section-number">21.4</span> RNNs in practice: GRU and LSTM</h2>
<p>Basic recurrent networks, as created by <code>nn_rnn()</code>, are nice for explanatory purposes, but hardly ever used in practice. The reason is that when you back-propagate through a long recurrence structure, gradients are likely to either “die” or get out of bounds. These are the so-called “vanishing gradient” and “exploding gradient” problems, respectively.</p>
<p>Already three decades before the compute- and big-data accelerated “era of deep learning”, an algorithmic solution had been found. <em>Long Short-Term Memory Networks</em>, described in <span class="citation" data-cites="hochreiter1997long">Hochreiter and Schmidhuber (<a href="references.html#ref-hochreiter1997long" role="doc-biblioref">1997</a>)</span>, enabled training on reasonably long sequences by introducing so-called <em>gates</em> that act as filters in various places of the state-threading calculation. <em>Gated Recurrent Units</em>, put forward (much more recently) in <span class="citation" data-cites="ChoMGBSB14">Cho et al. (<a href="references.html#ref-ChoMGBSB14" role="doc-biblioref">2014</a>)</span>, are similar in spirit, but a bit simpler. Together, both architectures dominate the space.</p>
<p>With these models introducing additional logic, we see how the division-of-labor strategy introduced above is useful: Iteration and state threading are taken care of by different modules. This means that, in principle, we could design our own LSTM or GRU <em>cell</em>, and then, iterate over it in the same fashion as before. Of course, there is no need to re-implement existing functionality. But following the same modularization approach, we can nicely experiment with variations to the processing logic if we want.</p>
<p>Now, let’s see what is returned by <code>nn_gru()</code> and <code>nn_lstm()</code>, the constructors corresponding to the aforementioned architectures. At this point, I should quickly comment on optional arguments I haven’t mentioned before.</p>
<p>In general, the argument list is the same for <code>nn_rnn()</code>, <code>nn_gru()</code>, and <code>nn_lstm()</code>.</p>
<p>We have to indicate the number of features (<code>input_size</code>) and the size of the state (<code>hidden_size</code>); we deliberately pass in <code>batch_first = TRUE;</code> we can have <code>torch</code> chain several RNNs together using <code>num_layers</code>. In case we <em>do</em> want to stack layers, we can drop out a fraction of interconnections using, well, <code>dropout</code>. Finally, there is <code>bidirectional</code>. By default, this argument is set to <code>FALSE</code>, meaning we’re passing through the sequence chronologically. With <code>bidirectional = TRUE</code>, there is an additional pass in reverse order, and weights from both passes are combined. Essentially, what we’re doing is predicting present from past as well as past from present. This may sound like “cheating”, but really, is not; it’s just making optimal use of dependencies in past data.</p>
<p>To keep our examples in sync, I’ll now instantiate the GRU and LSTM modules in the same way as <code>nn_rnn()</code> above, making use of single layer and a single direction.</p>
<p>First, a GRU:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>gru <span class="ot">&lt;-</span> <span class="fu">nn_gru</span>(</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">input_size =</span> <span class="dv">1</span>, </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">hidden_size =</span> <span class="dv">3</span>, </span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">batch_first =</span> <span class="cn">TRUE</span>,</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">num_layers =</span> <span class="dv">1</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>output <span class="ot">&lt;-</span> <span class="fu">gru</span>(<span class="fu">torch_randn</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>))</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co"># output</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(output[[<span class="dv">1</span>]]) <span class="co"># batch_size, timesteps, hidden_size</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co"># last hidden state (per layer)</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(output[[<span class="dv">2</span>]]) <span class="co"># num_layers, batch_size, hidden_size</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 2 4 3
[1] 1 2 3</code></pre>
<p>As you see, dimension-wise, the output returned from a GRU is analogous to that of a simple RNN.</p>
<p>With LSTM, however, we see a difference:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>lstm <span class="ot">&lt;-</span> <span class="fu">nn_lstm</span>(</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">input_size =</span> <span class="dv">1</span>,</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">hidden_size =</span> <span class="dv">3</span>,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">batch_first =</span> <span class="cn">TRUE</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>output <span class="ot">&lt;-</span> <span class="fu">lstm</span>(<span class="fu">torch_randn</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>))</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co"># output</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(output[[<span class="dv">1</span>]]) <span class="co"># batch_size, timesteps, hidden_size</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co"># last hidden state (per layer)</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(output[[<span class="dv">2</span>]][[<span class="dv">1</span>]]) <span class="co"># num_layers, batch_size, hidden_size</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="co"># last cell state (per layer)</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(output[[<span class="dv">2</span>]][[<span class="dv">2</span>]]) <span class="co"># num_layers, batch_size, hidden_size</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 2 4 3
[1] 1 2 3
[1] 1 2 3</code></pre>
<p>Instead of two, we now have three tensors. The first and second are no different from what we’ve seen so far; meaning, the second is as redundant as for a GRU or a simple RNN. (At least when there’s just a single layer). What about the third? Shape-wise, it looks like the second, the one we know returns the “hidden state”. In fact, it reflects an <em>additional</em> state, one not present in a GRU. And this one – often called <em>cell</em> state – <em>really</em> is available to the user only for the last time step, even for single-layer LSTMs.</p>
<p>You could say that with LSTMs, some hidden states are more hidden than others.</p>
<p>Now that we’ve gained some familiarity with <code>torch</code>’s RNN-related conventions, we look at an actual time series application.</p>
</section>
<section id="forecasting-electricity-demand" class="level2" data-number="21.5">
<h2 data-number="21.5" class="anchored" data-anchor-id="forecasting-electricity-demand"><span class="header-section-number">21.5</span> Forecasting electricity demand</h2>
<p>Our example time series, called <code>vic_elec</code>, is available from package <code>tsibbledata</code>. It reflects aggregated electricity demand for Victoria, Australia, measured in half-hour intervals. Additional features (which we won’t use here) include temperature and a holiday indicator. The dataset spans three years, ranging from January, 2012 to December, 2014.</p>
<p>Before we start, we need to define our task. In fact, there’ll be two of them. In both, we’ll attempt to predict future temperature based on past measurements. First, we’ll see how to predict the very next measurement; in terms of measurement intervals, that’s a single time step ahead. Then, we’ll modify the code to allow for forecasting several time steps in advance.</p>
<section id="data-inspection" class="level3" data-number="21.5.1">
<h3 data-number="21.5.1" class="anchored" data-anchor-id="data-inspection"><span class="header-section-number">21.5.1</span> Data inspection</h3>
<p>The dataset being part of an ecosystem of packages dedicated to time series analysis, there is not much to be done in terms of pre-processing. However, as always or even more so, it is worth our while to take time for data exploration.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tibble)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lubridate)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Tidy Temporal Data Frames and Tools</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tsibble) </span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature Extraction and Statistics for Time Series</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(feasts) </span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Diverse Datasets for 'tsibble'</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tsibbledata) </span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(torch)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(luz)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>vic_elec</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code># A tsibble: 52,608 x 5 [30m] &lt;Australia/Melbourne&gt;
   Time                Demand Temperature Date       Holiday
   &lt;dttm&gt;               &lt;dbl&gt;       &lt;dbl&gt; &lt;date&gt;     &lt;lgl&gt;  
 1 2012-01-01 00:00:00  4383.        21.4 2012-01-01 TRUE   
 2 2012-01-01 00:30:00  4263.        21.0 2012-01-01 TRUE   
 3 2012-01-01 01:00:00  4049.        20.7 2012-01-01 TRUE   
 4 2012-01-01 01:30:00  3878.        20.6 2012-01-01 TRUE   
 5 2012-01-01 02:00:00  4036.        20.4 2012-01-01 TRUE   
 6 2012-01-01 02:30:00  3866.        20.2 2012-01-01 TRUE   
 7 2012-01-01 03:00:00  3694.        20.1 2012-01-01 TRUE   
 8 2012-01-01 03:30:00  3562.        19.6 2012-01-01 TRUE   
 9 2012-01-01 04:00:00  3433.        19.1 2012-01-01 TRUE   
10 2012-01-01 04:30:00  3359.        19.0 2012-01-01 TRUE   
# … with 52,598 more rows</code></pre>
<p>Concretely, we’ll want to know what kinds of periodicities there are in the data. Conveniently, we can obtain a decomposition into trend, various seasonal components, and a remainder using <code>feasts::STL()</code>. Here’s what we see for a single year (<a href="#fig-timeseries-vic-elec-stl">fig.&nbsp;<span>21.1</span></a>):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>decomp <span class="ot">&lt;-</span> vic_elec <span class="sc">%&gt;%</span> </span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">year</span>(Date) <span class="sc">==</span> <span class="dv">2012</span>) <span class="sc">%&gt;%</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">model</span>(<span class="fu">STL</span>(Demand)) <span class="sc">%&gt;%</span> </span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">components</span>()</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>decomp <span class="sc">%&gt;%</span> <span class="fu">autoplot</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="fig-timeseries-vic-elec-stl" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/timeseries-vic-elec-stl.png" class="quarto-discovered-preview-image img-fluid figure-img" alt="Five rows, displaying different components of a time series. Row 1: Original data. Row 2: Trend; irregular. Row 3: Weekly pattern, strongly periodic. Row 4: Variation over the day; strongly periodic. Row 5: Half-hourly variation; irrelevant. Row 5: Reminder; irregular."></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;21.1: One year of electricity demand, decomposed into trend, seasonal components, and remainder.</figcaption><p></p>
</figure>
</div>
<p>In this plot, the scale bar on the left immediately signals a component’s importance: the smaller the bar, the more dominant the effect. Not surprisingly, day of week matters; so does time of day.</p>
<p>For greater granularity, we zoom in on a single month (<a href="#fig-timeseries-vic-elec-stl-month">fig.&nbsp;<span>21.2</span></a>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>decomp <span class="ot">&lt;-</span> vic_elec <span class="sc">%&gt;%</span> </span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">year</span>(Date) <span class="sc">==</span> <span class="dv">2012</span>, <span class="fu">month</span>(Date) <span class="sc">==</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">model</span>(<span class="fu">STL</span>(Demand)) <span class="sc">%&gt;%</span> </span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">components</span>()</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>decomp <span class="sc">%&gt;%</span> <span class="fu">autoplot</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="fig-timeseries-vic-elec-stl-month" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/timeseries-vic-elec-stl-month.png" class="img-fluid figure-img" alt="Five rows, displaying different components of a time series. Row 1: Original data. Row 2: Trend; shows decline over the first quarter of the month, then rises and stays on a high level, then starts falling again. Row 3: Weekly pattern, strongly periodic. Row 4: Variation over the day; strongly periodic. Row 5: Half-hourly variation; irrelevant. Row 5: Reminder; irregular."></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;21.2: A single month of electricity demand, decomposed into trend, seasonal components, and remainder.</figcaption><p></p>
</figure>
</div>
<p>Here, I’ve picked January, right in the hot Australian summer. Demand for electricity, then, arises as a need for cooling, not heating. We clearly see how it’s highest around noon, and lowest during the night. Every week, it peaks on Mondays and Tuesdays, declines on Wednesdays, and is more or less stable in the second half of the week.</p>
<p>Now, while those two periodicities are important, the half-hourly rhythm clearly isn’t. For training the network, I’ll thus aggregate pairs of adjacent values, reducing the number of measurements to a half. Since now, changes between consecutive values are bigger, this also makes the task harder.</p>
</section>
<section id="forecasting-the-very-next-value" class="level3" data-number="21.5.2">
<h3 data-number="21.5.2" class="anchored" data-anchor-id="forecasting-the-very-next-value"><span class="header-section-number">21.5.2</span> Forecasting the very next value</h3>
<p>We start with the more modest goal: predicting the very next data point. First of all, we need a custom <code>torch::dataset()</code>.</p>
<section id="a-dataset-for-single-step-prediction" class="level4" data-number="21.5.2.1">
<h4 data-number="21.5.2.1" class="anchored" data-anchor-id="a-dataset-for-single-step-prediction"><span class="header-section-number">21.5.2.1</span> A <code>dataset()</code> for single-step prediction</h4>
<p>In our demonstration of how <code>torch</code> RNNs work, we made use of a toy data tensor that looked like this: <code>torch_randn(2, 4, 1)</code>.</p>
<p>Here, the first dimension corresponded to batch items; the second, to time steps; and the third, to features. The batch dimension will be taken care of by the <code>dataloader()</code>. Thus, for the <code>dataset()</code>, the task to return a single predictor reduces to picking just as many consecutive measurements as desired, and stacking them in the first dimension. The corresponding target, in this first setup, should be the single measurement right after the last step in the predictor sequence.</p>
<p>So in principle, <code>.getitem()</code>, when asked for the item at position <code>i</code>, should return the following:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">list</span>(</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> self<span class="sc">$</span>x[i<span class="sc">:</span>(i <span class="sc">+</span> self<span class="sc">$</span>n_timesteps <span class="sc">-</span> <span class="dv">1</span>)],</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> self<span class="sc">$</span>x[self<span class="sc">$</span>n_timesteps <span class="sc">+</span> i]</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The code you’ll find below is a variation on this theme. Depending on the time series in question, stacking consecutive measurements like this may result in individual batches looking hardly any different from each other. To avoid redundancy, we could do the following: Instead of iterating over the series in order, we take samples. At construction time, the <code>torch::dataset()</code> is told what fraction of the data we’d like to be served in each epoch, and prepares a set of indices. Then at runtime, it iterates over those indices. In the present case, sampling is not really needed, since anyway we’ve decided on hourly aggregation, and the time series itself isn’t excessively long to start with. The reason I’m showing this technique is that you might find it useful in other applications.</p>
<p>Now, take a look at how we initialize the <code>dataset()</code>. If it is supposed to stack consecutive measurements, it has to be told the desired number of time steps. For easy experimentation, we make that parameter (called <code>n_timesteps</code>) a constructor argument.</p>
<p>Here is the complete <code>dataset()</code> code:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>demand_dataset <span class="ot">&lt;-</span> <span class="fu">dataset</span>(</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">name =</span> <span class="st">"demand_dataset"</span>,</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">initialize =</span> <span class="cf">function</span>(x, n_timesteps, <span class="at">sample_frac =</span> <span class="dv">1</span>) {</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>n_timesteps <span class="ot">&lt;-</span> n_timesteps</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>x <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>((x <span class="sc">-</span> train_mean) <span class="sc">/</span> train_sd)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    n <span class="ot">&lt;-</span> <span class="fu">length</span>(self<span class="sc">$</span>x) <span class="sc">-</span> self<span class="sc">$</span>n_timesteps</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>starts <span class="ot">&lt;-</span> <span class="fu">sort</span>(<span class="fu">sample.int</span>(</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n,</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">size =</span> n <span class="sc">*</span> sample_frac</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">.getitem =</span> <span class="cf">function</span>(i) {</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    start <span class="ot">&lt;-</span> self<span class="sc">$</span>starts[i]</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    end <span class="ot">&lt;-</span> start <span class="sc">+</span> self<span class="sc">$</span>n_timesteps <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">list</span>(</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> self<span class="sc">$</span>x[start<span class="sc">:</span>end],</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> self<span class="sc">$</span>x[end <span class="sc">+</span> <span class="dv">1</span>]</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">.length =</span> <span class="cf">function</span>() {</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">length</span>(self<span class="sc">$</span>starts)</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Given that <code>vic_elec</code> holds three years of data, a by-year split into training, validation, and test sets seems to suggest itself. Here, we perform the split, right after aggregating by full hour:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>demand_hourly <span class="ot">&lt;-</span> vic_elec <span class="sc">%&gt;%</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">index_by</span>(<span class="at">Hour =</span> <span class="fu">floor_date</span>(Time, <span class="st">"hour"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">Demand =</span> <span class="fu">sum</span>(Demand))</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>demand_train <span class="ot">&lt;-</span> demand_hourly <span class="sc">%&gt;%</span> </span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">year</span>(Hour) <span class="sc">==</span> <span class="dv">2012</span>) <span class="sc">%&gt;%</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Demand) <span class="sc">%&gt;%</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>()</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>demand_valid <span class="ot">&lt;-</span> demand_hourly <span class="sc">%&gt;%</span> </span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">year</span>(Hour) <span class="sc">==</span> <span class="dv">2013</span>) <span class="sc">%&gt;%</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Demand) <span class="sc">%&gt;%</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>()</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>demand_test <span class="ot">&lt;-</span> demand_hourly <span class="sc">%&gt;%</span> </span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">year</span>(Hour) <span class="sc">==</span> <span class="dv">2014</span>) <span class="sc">%&gt;%</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Demand) <span class="sc">%&gt;%</span></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In the <code>dataset()</code> definition, you may have noticed the use of <code>train_mean</code> and <code>train_sd</code> to standardize the data. Time to compute them:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>train_mean <span class="ot">&lt;-</span> <span class="fu">mean</span>(demand_train)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>train_sd <span class="ot">&lt;-</span> <span class="fu">sd</span>(demand_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we’re all set to construct the <code>dataset()</code> objects – but for one decision: What is a good value for <code>n_timesteps</code>? As with every hyper-parameter, in the end, nothing can beat experimentation. But based on data exploration, we can establish a lower bound: We definitely want to capture variation over day <em>and</em> week. With the hourly-aggregated data, this gives us a minimum length of 168:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>n_timesteps <span class="ot">&lt;-</span> <span class="dv">7</span> <span class="sc">*</span> <span class="dv">24</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we instantiate the <code>dataset()</code> objects, and immediately check tensor shapes:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>train_ds <span class="ot">&lt;-</span> <span class="fu">demand_dataset</span>(demand_train, n_timesteps)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>valid_ds <span class="ot">&lt;-</span> <span class="fu">demand_dataset</span>(demand_valid, n_timesteps)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>test_ds <span class="ot">&lt;-</span> <span class="fu">demand_dataset</span>(demand_test, n_timesteps)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(train_ds[<span class="dv">1</span>]<span class="sc">$</span>x)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(train_ds[<span class="dv">1</span>]<span class="sc">$</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 168   1
[1] 1</code></pre>
<p>Next, the respective <code>dataloader()</code>s:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">&lt;-</span> <span class="dv">128</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>train_dl <span class="ot">&lt;-</span> train_ds <span class="sc">%&gt;%</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dataloader</span>(<span class="at">batch_size =</span> batch_size, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>valid_dl <span class="ot">&lt;-</span> valid_ds <span class="sc">%&gt;%</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dataloader</span>(<span class="at">batch_size =</span> batch_size)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>test_dl <span class="ot">&lt;-</span> test_ds <span class="sc">%&gt;%</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dataloader</span>(<span class="at">batch_size =</span> <span class="fu">length</span>(test_ds))</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> train_dl <span class="sc">%&gt;%</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dataloader_make_iter</span>() <span class="sc">%&gt;%</span></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dataloader_next</span>()</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(b<span class="sc">$</span>x)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(b<span class="sc">$</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>[1] 128 168   1
[1] 128   1</code></pre>
<p>Once we’re dealing with batches we <em>do</em> see the required three-dimensional structure of the input tensor.</p>
</section>
<section id="model" class="level4" data-number="21.5.2.2">
<h4 data-number="21.5.2.2" class="anchored" data-anchor-id="model"><span class="header-section-number">21.5.2.2</span> Model</h4>
<p>In the model, the main workhorse is the LSTM. The number of LSTM-internal layers is configurable, the default being set to one. Its final output (or: “hidden state”; more on that below) is passed on to a linear module that outputs a single prediction.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">nn_module</span>(</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">initialize =</span> <span class="cf">function</span>(input_size,</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>                        hidden_size,</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>                        <span class="at">dropout =</span> <span class="fl">0.2</span>,</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>                        <span class="at">num_layers =</span> <span class="dv">1</span>,</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>                        <span class="at">rec_dropout =</span> <span class="dv">0</span>) {</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>num_layers <span class="ot">&lt;-</span> num_layers</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>rnn <span class="ot">&lt;-</span> <span class="fu">nn_lstm</span>(</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">input_size =</span> input_size,</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">hidden_size =</span> hidden_size,</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">num_layers =</span> num_layers,</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">dropout =</span> rec_dropout,</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">batch_first =</span> <span class="cn">TRUE</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>dropout <span class="ot">&lt;-</span> <span class="fu">nn_dropout</span>(dropout)</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>output <span class="ot">&lt;-</span> <span class="fu">nn_linear</span>(hidden_size, <span class="dv">1</span>)</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">forward =</span> <span class="cf">function</span>(x) {</span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>    (x <span class="sc">%&gt;%</span></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>      <span class="co"># these two are equivalent</span></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a>      <span class="co"># (1)</span></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>      <span class="co"># take output tensor,restrict to last time step</span></span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span><span class="fu">rnn</span>())[[<span class="dv">1</span>]][, <span class="fu">dim</span>(x)[<span class="dv">2</span>], ] <span class="sc">%&gt;%</span></span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a>      <span class="co"># (2)</span></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a>      <span class="co"># from list of state tensors,take the first,</span></span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a>      <span class="co"># and pick the final layer</span></span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a>      <span class="co"># self$rnn())[[2]][[1]][self$num_layers, , ] %&gt;%</span></span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span><span class="fu">dropout</span>() <span class="sc">%&gt;%</span></span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span><span class="fu">output</span>()</span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note two things about the top-level module’s definition. First, its constructor accepts two dropout-related arguments. The first, <code>dropout</code>, specifies the fraction of elements to be zeroed out on the path between LSTM and linear module; the second, <code>rec_dropout</code>, gets passed on to the LSTM, to be made use of between individual layers. (If there is just a single layer, this parameter has to equal zero, its default.)</p>
<p>Secondly, in <code>forward()</code>, I’m showing two equivalent ways to pass output from the LSTM to the linear module. We can either ask <code>torch</code> for “the output”, and then, take the subset of values corresponding to the last time step only; alternatively, we can extract the “hidden state” tensor and zoom in on the final layer. Of course, since whatever choice we make is fine, there is no need to complicate the decision; I merely wanted to take the occasion to, one final time, illustrate how to “talk RNN” with <code>torch</code>.</p>
</section>
<section id="training" class="level4" data-number="21.5.2.3">
<h4 data-number="21.5.2.3" class="anchored" data-anchor-id="training"><span class="header-section-number">21.5.2.3</span> Training</h4>
<p>Like so often, we start the training process by running the learning rate finder. The model we’re training is modest in size (12,928 parameters overall!), but powerful – not in the least due to the stacking of LSTM layers.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>input_size <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>hidden_size <span class="ot">&lt;-</span> <span class="dv">32</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>num_layers <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>rec_dropout <span class="ot">&lt;-</span> <span class="fl">0.2</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">setup</span>(<span class="at">optimizer =</span> optim_adam, <span class="at">loss =</span> <span class="fu">nn_mse_loss</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_hparams</span>(</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">input_size =</span> input_size,</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">hidden_size =</span> hidden_size,</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">num_layers =</span> num_layers,</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">rec_dropout =</span> rec_dropout</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>rates_and_losses <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> </span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lr_finder</span>(train_dl, <span class="at">start_lr =</span> <span class="fl">1e-3</span>, <span class="at">end_lr =</span> <span class="dv">1</span>)</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>rates_and_losses <span class="sc">%&gt;%</span> <span class="fu">plot</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="fig-timeseries-vic-elec-lr-finder" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/timeseries-vic-elec-lr-finder.png" class="img-fluid figure-img" alt="A curve that, from left to right, first slowly declines (until about x=0.3), then begins to rise sharply, exhibiting high variability."></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;21.3: Learning rate finder output for the one-step-ahead-forecast model.</figcaption><p></p>
</figure>
</div>
<p>From the plot (<a href="#fig-timeseries-vic-elec-lr-finder">fig.&nbsp;<span>21.3</span></a>), a maximal learning rate of 0.1 seems like a sensible choice, at least when combined with the one-cycle learning rate scheduler. Indeed, we see fast progress (<a href="#fig-timeseries-vic-elec-fit">fig.&nbsp;<span>21.4</span></a>):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>fitted <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(train_dl, <span class="at">epochs =</span> <span class="dv">50</span>, <span class="at">valid_data =</span> valid_dl,</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">callbacks =</span> <span class="fu">list</span>(</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>        <span class="fu">luz_callback_early_stopping</span>(<span class="at">patience =</span> <span class="dv">3</span>),</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>        <span class="fu">luz_callback_lr_scheduler</span>(</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>          lr_one_cycle,</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>          <span class="at">max_lr =</span> <span class="fl">0.1</span>,</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">epochs =</span> <span class="dv">50</span>,</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>          <span class="at">steps_per_epoch =</span> <span class="fu">length</span>(train_dl),</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>          <span class="at">call_on =</span> <span class="st">"on_batch_end"</span>)</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>      ),</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">verbose =</span> <span class="cn">TRUE</span>)</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fitted)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>Epoch 1/50
Train metrics: Loss: 0.3119
Valid metrics: Loss: 0.0715
Epoch 2/50
Train metrics: Loss: 0.0767
Valid metrics: Loss: 0.0562
...
...
Epoch 17/50
Train metrics: Loss: 0.0301
Valid metrics: Loss: 0.0295
Epoch 18/50
Train metrics: Loss: 0.0288 
Valid metrics: Loss: 0.0263
Early stopping at epoch 18 of 50</code></pre>
<div id="fig-timeseries-vic-elec-fit" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/timeseries-vic-elec-fit.png" class="img-fluid figure-img" alt="Curves representing training and validation loss. The training curve falls sharply, in just one epoch. Thereafter, it keeps descending, but slowly. The validation curve looks similar, apart from not showing the initial decline."></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;21.4: Fitting a one-step forecast model on <code>vic_elec</code>.</figcaption><p></p>
</figure>
</div>
</section>
<section id="inspecting-predictions" class="level4" data-number="21.5.2.4">
<h4 data-number="21.5.2.4" class="anchored" data-anchor-id="inspecting-predictions"><span class="header-section-number">21.5.2.4</span> Inspecting predictions</h4>
<p>Using <code>luz::evaluate()</code>, we can check whether performance on the test set approximately matches that on the validation set. Here is mean squared error, as obtained from test-set predictions:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">evaluate</span>(fitted, test_dl)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>A `luz_module_evaluation`
── Results ───────────────────────────────────────────────
loss: 0.0364</code></pre>
<p>But really, what does this value tell us? We need to actually <em>look</em> at forecasts to decide whether predictions are any good.</p>
<p>For visualization, let’s choose a subset of the test data – the final month, say. We obtain predictions, and display them together with the actual measurements (<a href="#fig-timeseries-vic-elec-preds">fig.&nbsp;<span>21.5</span></a>):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>demand_viz <span class="ot">&lt;-</span> demand_hourly <span class="sc">%&gt;%</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">year</span>(Hour) <span class="sc">==</span> <span class="dv">2014</span>, <span class="fu">month</span>(Hour) <span class="sc">==</span> <span class="dv">12</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>demand_viz_matrix <span class="ot">&lt;-</span> demand_viz <span class="sc">%&gt;%</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Demand) <span class="sc">%&gt;%</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>()</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>viz_ds <span class="ot">&lt;-</span> <span class="fu">demand_dataset</span>(demand_viz_matrix, n_timesteps)</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>viz_dl <span class="ot">&lt;-</span> viz_ds <span class="sc">%&gt;%</span> <span class="fu">dataloader</span>(<span class="at">batch_size =</span> <span class="fu">length</span>(viz_ds))</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fitted, viz_dl)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> preds<span class="sc">$</span><span class="fu">to</span>(<span class="at">device =</span> <span class="st">"cpu"</span>) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="cn">NA</span>, n_timesteps), preds)</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>pred_ts <span class="ot">&lt;-</span> demand_viz <span class="sc">%&gt;%</span></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_column</span>(<span class="at">forecast =</span> preds <span class="sc">*</span> train_sd <span class="sc">+</span> train_mean) <span class="sc">%&gt;%</span></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="sc">-</span>Hour) <span class="sc">%&gt;%</span></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_tsibble</span>(<span class="at">key =</span> name)</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>pred_ts <span class="sc">%&gt;%</span></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>() <span class="sc">+</span></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_colour_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"#08c5d1"</span>, <span class="st">"#00353f"</span>)) <span class="sc">+</span></span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"None"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="fig-timeseries-vic-elec-preds" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/timeseries-vic-elec-preds.png" class="img-fluid figure-img" alt="Hourly temperatures during the test period, plus forecasts obtained for weeks two to four. Forecasts hardly deviate from actual measurements."></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;21.5: One-step ahead forecast on the last month of test set.</figcaption><p></p>
</figure>
</div>
<p>Predictions look good! However, we know this was the simpler task of the two.</p>
</section>
</section>
<section id="forecasting-multiple-time-steps-ahead" class="level3" data-number="21.5.3">
<h3 data-number="21.5.3" class="anchored" data-anchor-id="forecasting-multiple-time-steps-ahead"><span class="header-section-number">21.5.3</span> Forecasting multiple time steps ahead</h3>
<p>In reality, being able to predict a single measurement may not necessarily be of great use. Fortunately, not much adaptation is required to obtain multiple predictions from this type of model. In principle, we just have to modify the output size of the final linear layer. For performance reasons, we’ll go a bit further, but it’ll still be a moderate change.</p>
<p>Since the target now is a sequence, we also have to adapt the <code>dataset()</code>.</p>
<section id="dataset-adaptation" class="level4" data-number="21.5.3.1">
<h4 data-number="21.5.3.1" class="anchored" data-anchor-id="dataset-adaptation"><span class="header-section-number">21.5.3.1</span> <code>Dataset()</code> adaptation</h4>
<p>Just like the number of consecutive measurements in an input tensor, that of the target tensors should be configurable. We therefore introduce a new parameter, <code>n_forecast</code>, that indicates the desired length:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>demand_dataset <span class="ot">&lt;-</span> <span class="fu">dataset</span>(</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">name =</span> <span class="st">"demand_dataset"</span>,</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">initialize =</span> <span class="cf">function</span>(x,</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>                        n_timesteps,</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>                        n_forecast,</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>                        <span class="at">sample_frac =</span> <span class="dv">1</span>) {</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>n_timesteps <span class="ot">&lt;-</span> n_timesteps</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>n_forecast <span class="ot">&lt;-</span> n_forecast</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>x <span class="ot">&lt;-</span> <span class="fu">torch_tensor</span>((x <span class="sc">-</span> train_mean) <span class="sc">/</span> train_sd)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>    n <span class="ot">&lt;-</span> <span class="fu">length</span>(self<span class="sc">$</span>x) <span class="sc">-</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span>n_timesteps <span class="sc">-</span> self<span class="sc">$</span>n_forecast <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>starts <span class="ot">&lt;-</span> <span class="fu">sort</span>(<span class="fu">sample.int</span>(</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">n =</span> n,</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">size =</span> n <span class="sc">*</span> sample_frac</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">.getitem =</span> <span class="cf">function</span>(i) {</span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a>    start <span class="ot">&lt;-</span> self<span class="sc">$</span>starts[i]</span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a>    end <span class="ot">&lt;-</span> start <span class="sc">+</span> self<span class="sc">$</span>n_timesteps <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">list</span>(</span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> self<span class="sc">$</span>x[start<span class="sc">:</span>end],</span>
<span id="cb41-25"><a href="#cb41-25" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> self<span class="sc">$</span>x[(end <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">:</span>(end <span class="sc">+</span> self<span class="sc">$</span>n_forecast)]<span class="sc">$</span></span>
<span id="cb41-26"><a href="#cb41-26" aria-hidden="true" tabindex="-1"></a>        <span class="fu">squeeze</span>(<span class="dv">2</span>)</span>
<span id="cb41-27"><a href="#cb41-27" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb41-28"><a href="#cb41-28" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb41-29"><a href="#cb41-29" aria-hidden="true" tabindex="-1"></a>  <span class="at">.length =</span> <span class="cf">function</span>() {</span>
<span id="cb41-30"><a href="#cb41-30" aria-hidden="true" tabindex="-1"></a>    <span class="fu">length</span>(self<span class="sc">$</span>starts)</span>
<span id="cb41-31"><a href="#cb41-31" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb41-32"><a href="#cb41-32" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We’ll attempt to forecast demand for the subsequent seven days. Thus, <code>n_timesteps</code> and <code>n_forecast</code> are equal; but that’s a coincidence, not a requirement.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>n_timesteps <span class="ot">&lt;-</span> <span class="dv">7</span> <span class="sc">*</span> <span class="dv">24</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>n_forecast <span class="ot">&lt;-</span> <span class="dv">7</span> <span class="sc">*</span> <span class="dv">24</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>train_ds <span class="ot">&lt;-</span> <span class="fu">demand_dataset</span>(</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>  demand_train,</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>  n_timesteps,</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>  n_forecast,</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_frac =</span> <span class="dv">1</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>valid_ds <span class="ot">&lt;-</span> <span class="fu">demand_dataset</span>(</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>  demand_valid,</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>  n_timesteps,</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>  n_forecast,</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_frac =</span> <span class="dv">1</span></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>test_ds <span class="ot">&lt;-</span> <span class="fu">demand_dataset</span>(</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>  demand_test,</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>  n_timesteps,</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>  n_forecast</span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>batch_size <span class="ot">&lt;-</span> <span class="dv">128</span></span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a>train_dl <span class="ot">&lt;-</span> train_ds <span class="sc">%&gt;%</span></span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dataloader</span>(<span class="at">batch_size =</span> batch_size, <span class="at">shuffle =</span> <span class="cn">TRUE</span>)</span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>valid_dl <span class="ot">&lt;-</span> valid_ds <span class="sc">%&gt;%</span></span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dataloader</span>(<span class="at">batch_size =</span> batch_size)</span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a>test_dl <span class="ot">&lt;-</span> test_ds <span class="sc">%&gt;%</span></span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dataloader</span>(<span class="at">batch_size =</span> <span class="fu">length</span>(test_ds))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="model-adaptation" class="level4" data-number="21.5.3.2">
<h4 data-number="21.5.3.2" class="anchored" data-anchor-id="model-adaptation"><span class="header-section-number">21.5.3.2</span> Model adaptation</h4>
<p>In the model, we replace the final linear layer by a tiny multi-layer perceptron. It will return <code>n_forecast</code> predictions for each time step.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">nn_module</span>(</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">initialize =</span> <span class="cf">function</span>(input_size,</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>                        hidden_size,</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>                        linear_size,</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>                        output_size,</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>                        <span class="at">dropout =</span> <span class="fl">0.2</span>,</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>                        <span class="at">num_layers =</span> <span class="dv">1</span>,</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>                        <span class="at">rec_dropout =</span> <span class="dv">0</span>) {</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>num_layers <span class="ot">&lt;-</span> num_layers</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>rnn <span class="ot">&lt;-</span> <span class="fu">nn_lstm</span>(</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">input_size =</span> input_size,</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">hidden_size =</span> hidden_size,</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">num_layers =</span> num_layers,</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">dropout =</span> rec_dropout,</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">batch_first =</span> <span class="cn">TRUE</span></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>dropout <span class="ot">&lt;-</span> <span class="fu">nn_dropout</span>(dropout)</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>    self<span class="sc">$</span>mlp <span class="ot">&lt;-</span> <span class="fu">nn_sequential</span>(</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>      <span class="fu">nn_linear</span>(hidden_size, linear_size),</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>      <span class="fu">nn_relu</span>(),</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>      <span class="fu">nn_dropout</span>(dropout),</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>      <span class="fu">nn_linear</span>(linear_size, output_size)</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>  },</span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">forward =</span> <span class="cf">function</span>(x) {</span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> self<span class="sc">$</span><span class="fu">rnn</span>(x)[[<span class="dv">2</span>]][[<span class="dv">1</span>]][self<span class="sc">$</span>num_layers, , ] <span class="sc">%&gt;%</span></span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>      self<span class="sc">$</span><span class="fu">mlp</span>()</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="training-1" class="level4" data-number="21.5.3.3">
<h4 data-number="21.5.3.3" class="anchored" data-anchor-id="training-1"><span class="header-section-number">21.5.3.3</span> Training</h4>
<p>Not surprisingly, the training process is unaltered. It again starts with running the learning rate finder (<a href="#fig-vic-elec-lr-finder-mlp">fig.&nbsp;<span>21.6</span></a>):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>input_size <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>hidden_size <span class="ot">&lt;-</span> <span class="dv">32</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>linear_size <span class="ot">&lt;-</span> <span class="dv">512</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>dropout <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>num_layers <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>rec_dropout <span class="ot">&lt;-</span> <span class="fl">0.2</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">setup</span>(<span class="at">optimizer =</span> optim_adam, <span class="at">loss =</span> <span class="fu">nn_mse_loss</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_hparams</span>(</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">input_size =</span> input_size,</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">hidden_size =</span> hidden_size,</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">linear_size =</span> linear_size,</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">output_size =</span> n_forecast,</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">num_layers =</span> num_layers,</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">rec_dropout =</span> rec_dropout</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>rates_and_losses <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span> <span class="fu">lr_finder</span>(</span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>  train_dl,</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">start_lr =</span> <span class="fl">1e-4</span>,</span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">end_lr =</span> <span class="fl">0.5</span></span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>rates_and_losses <span class="sc">%&gt;%</span> <span class="fu">plot</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="fig-vic-elec-lr-finder-mlp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/timeseries-vic-elec-lr-finder-mlp.png" class="img-fluid figure-img" alt="A highly fluctuating curve that, from left to right, first stays constant, then declines (until about x=0.05), then begins to rise sharply, exhibiting high variability."></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;21.6: Learning rate finder output for multiple-step prediction.</figcaption><p></p>
</figure>
</div>
<p>Based on that result, I’ll go with a lower maximal rate this time.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>fitted <span class="ot">&lt;-</span> model <span class="sc">%&gt;%</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(train_dl, <span class="at">epochs =</span> <span class="dv">100</span>, <span class="at">valid_data =</span> valid_dl,</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">callbacks =</span> <span class="fu">list</span>(</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>        <span class="fu">luz_callback_early_stopping</span>(<span class="at">patience =</span> <span class="dv">3</span>),</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>        <span class="fu">luz_callback_lr_scheduler</span>(</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>          lr_one_cycle,</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>          <span class="at">max_lr =</span> <span class="fl">0.01</span>,</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>          <span class="at">epochs =</span> <span class="dv">100</span>,</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>          <span class="at">steps_per_epoch =</span> <span class="fu">length</span>(train_dl),</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>          <span class="at">call_on =</span> <span class="st">"on_batch_end"</span>)</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>      ),</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">verbose =</span> <span class="cn">TRUE</span>)</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fitted)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>Epoch 1/100
Train metrics: Loss: 0.9639                             
Valid metrics: Loss: 0.9714
Epoch 2/100
Train metrics: Loss: 0.823                              
Valid metrics: Loss: 0.7729
...
...
Epoch 21/100
Train metrics: Loss: 0.3833                             
Valid metrics: Loss: 0.4585
Epoch 22/100
Train metrics: Loss: 0.3796                             
Valid metrics: Loss: 0.4404
...
...
Epoch 41/100
Train metrics: Loss: 0.3103                             
Valid metrics: Loss: 0.3677
Epoch 42/100
Train metrics: Loss: 0.3089                             
Valid metrics: Loss: 0.3646
...
...
Epoch 60/100
Train metrics: Loss: 0.2707                             
Valid metrics: Loss: 0.3337
Epoch 61/100
Train metrics: Loss: 0.2617                             
Valid metrics: Loss: 0.3317
Early stopping at epoch 61 of 100</code></pre>
<div id="fig-timeseries-vic-elec-fit-mlp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/timeseries-vic-elec-fit-mlp.png" class="img-fluid figure-img" alt="Curves representing training and validation loss. The training curve falls sharply, in very few epochs. Thereafter, it keeps descending, but less fast, until it slowly flattens. The validation curve looks similar."></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;21.7: Fitting a multiple-step forecast model on vic_elec.</figcaption><p></p>
</figure>
</div>
<p>The loss curves (<a href="#fig-timeseries-vic-elec-fit-mlp">fig.&nbsp;<span>21.7</span></a>) look decent; how about actual forecasts?</p>
</section>
<section id="inspecting-predictions-1" class="level4" data-number="21.5.3.4">
<h4 data-number="21.5.3.4" class="anchored" data-anchor-id="inspecting-predictions-1"><span class="header-section-number">21.5.3.4</span> Inspecting predictions</h4>
<p>As before, let’s first formally check that performance on the test set does not differ too much from that on the validation set.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">evaluate</span>(fitted, test_dl)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>A `luz_module_evaluation`
── Results ───────────────────────────────────────────────
loss: 0.3782</code></pre>
<p>For visualization, we again look at the very last month only.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>demand_viz <span class="ot">&lt;-</span> demand_hourly <span class="sc">%&gt;%</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">year</span>(Hour) <span class="sc">==</span> <span class="dv">2014</span>, <span class="fu">month</span>(Hour) <span class="sc">==</span> <span class="dv">12</span>)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>demand_viz_matrix <span class="ot">&lt;-</span> demand_viz <span class="sc">%&gt;%</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Demand) <span class="sc">%&gt;%</span></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>()</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>n_obs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(demand_viz_matrix)</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>viz_ds <span class="ot">&lt;-</span> <span class="fu">demand_dataset</span>(</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>  demand_viz_matrix,</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>  n_timesteps,</span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>  n_forecast</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>viz_dl <span class="ot">&lt;-</span> viz_ds <span class="sc">%&gt;%</span></span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dataloader</span>(<span class="at">batch_size =</span> <span class="fu">length</span>(viz_ds))</span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(fitted, viz_dl)</span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> preds<span class="sc">$</span><span class="fu">to</span>(<span class="at">device =</span> <span class="st">"cpu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With each forecast now covering a week of measurements, we can’t display them all in the same plot. What we <em>can</em> do is pick a few sample indices, nicely spread out over the month, and plot those (<a href="#fig-timeseries-vic-elec-preds-mlp">fig.&nbsp;<span>21.8</span></a>):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>example_preds <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="at">mode =</span> <span class="st">"list"</span>, <span class="at">length =</span> <span class="dv">3</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>example_indices <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">201</span>, <span class="dv">401</span>)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_along</span>(example_indices)) {</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>  cur_obs <span class="ot">&lt;-</span> example_indices[i]</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>  example_preds[[i]] <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rep</span>(<span class="cn">NA</span>, n_timesteps <span class="sc">+</span> cur_obs <span class="sc">-</span> <span class="dv">1</span>),</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>    preds[cur_obs, ],</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rep</span>(</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>      <span class="cn">NA</span>,</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>      n_obs <span class="sc">-</span> cur_obs <span class="sc">+</span> <span class="dv">1</span> <span class="sc">-</span> n_timesteps <span class="sc">-</span> n_forecast</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>pred_ts <span class="ot">&lt;-</span> demand_viz <span class="sc">%&gt;%</span></span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Demand) <span class="sc">%&gt;%</span></span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_column</span>(</span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">p1 =</span> example_preds[[<span class="dv">1</span>]] <span class="sc">*</span> train_sd <span class="sc">+</span> train_mean,</span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">p2 =</span> example_preds[[<span class="dv">2</span>]] <span class="sc">*</span> train_sd <span class="sc">+</span> train_mean,</span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">p3 =</span> example_preds[[<span class="dv">3</span>]] <span class="sc">*</span> train_sd <span class="sc">+</span> train_mean) <span class="sc">%&gt;%</span></span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="sc">-</span>Hour) <span class="sc">%&gt;%</span></span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_tsibble</span>(<span class="at">key =</span> name)</span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a>pred_ts <span class="sc">%&gt;%</span></span>
<span id="cb50-26"><a href="#cb50-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autoplot</span>() <span class="sc">+</span></span>
<span id="cb50-27"><a href="#cb50-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_colour_manual</span>(</span>
<span id="cb50-28"><a href="#cb50-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(</span>
<span id="cb50-29"><a href="#cb50-29" aria-hidden="true" tabindex="-1"></a>      <span class="st">"#08c5d1"</span>, <span class="st">"#00353f"</span>, <span class="st">"#ffbf66"</span>, <span class="st">"#d46f4d"</span></span>
<span id="cb50-30"><a href="#cb50-30" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb50-31"><a href="#cb50-31" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb50-32"><a href="#cb50-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb50-33"><a href="#cb50-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"None"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="fig-timeseries-vic-elec-preds-mlp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/timeseries-vic-elec-preds-mlp.png" class="img-fluid figure-img" alt="Hourly temperatures during the test period, plus forecasts obtained for weeks two to four. Forecasts are of varying quality."></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;21.8: A sample of week-long forecasts on the last month of test set.</figcaption><p></p>
</figure>
</div>
<p>It is instructive to take a closer look. The daily and weekly rhythms are present; very much so in fact. What’s harder to devine, from the model’s point of view, are the mini-trends we see developing over the month. Without any external “cues”, how should it know that next week, demand for electricity will raise over (or fall below) the current level? To significantly improve predictions, we would have to incorporate additional data – for example, temperature forecasts. Since no book can cover everything, we won’t pursue that topic here; instead, we’ll move on to our last deep learning application: classifying speech utterances.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-ChoMGBSB14" class="csl-entry" role="listitem">
Cho, Kyunghyun, Bart van Merrienboer, Çaglar Gülçehre, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. <span>“Learning Phrase Representations Using <span>RNN</span> Encoder-Decoder for Statistical Machine Translation.”</span> <em>CoRR</em> abs/1406.1078. <a href="http://arxiv.org/abs/1406.1078">http://arxiv.org/abs/1406.1078</a>.
</div>
<div id="ref-hochreiter1997long" class="csl-entry" role="listitem">
Hochreiter, Sepp, and Jürgen Schmidhuber. 1997. <span>“Long Short-Term Memory.”</span> <em>Neural Computation</em> 9 (8): 1735–80.
</div>
</div>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./tabular_data.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Tabular data</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./audio_classification.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Audio classification</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>